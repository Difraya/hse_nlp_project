{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Базовая линейная модель"
      ],
      "metadata": {
        "id": "onOe8PUg1G2y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "В этом ноутбуке содержится код базовой линейной модели, которая показала наивысшее качество в результате ряда экспериментов, которые содержатся в отдельном ноутбуке Voronik_experiments.ipynb, а также проверочный код для инференса, кторый можно протестировать не ожидая обучения модели, так как к ноутбуку также приложен файл pipeline.pkl, который достаточно загрузить для выполнения инференса."
      ],
      "metadata": {
        "id": "rHpp5KuE1P0N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "from collections import Counter\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "6AMdYyOdzDYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "yZWLoWYDzFH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выполним загрузку ранее полученных файлов содержащих тренировочный и тестовый датасет. В тренировочном датасете содержатся 100 книг различных авторов, по одной книге, каждого автора (те по 1 объекту, каждого из 100 классов), а в тестовом датасете 51 книга части этих же авторов, но не та, которая попала в тренировочный набор. Обучение модели было выполнено на текстах книг, которые были очищены от метаданных и пробельных символов, а также обрезаны до максимальной длинны слов в 200000."
      ],
      "metadata": {
        "id": "WyPh9fho2T48"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_parquet('//content//drive//MyDrive//AI//NLP//df_train.pq')\n",
        "df_test = pd.read_parquet('//content//drive//MyDrive//AI//NLP//df_test.pq')"
      ],
      "metadata": {
        "id": "L11bml6QzRhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Описание признаков тренировочного и тестового датасетов\n",
        "1.  'author' - имя и фамилия автора **(целевая переменная 100 классов)**\n",
        "2.  'text_' - оригинальный полный текст книги без пробельных символов и метаданных\n",
        "3.  'cnt_sent' - количество предложений\n",
        "4.  'text_len' - количество символов в оригинальном тексте, до обрезки\n",
        "5.  'text' - обрезанный в середине текст книги до максимальной длинны в 200000 слов\n",
        "6.  'text_len2' - количество символов в \"text\"\n",
        "7.  'words_cnt' - количество слов в обрезанном тексте\n",
        "8.  'wrds_sent_cnt' - отношение количества слов к количеству предложений, или средняя длина предложения\n",
        "9.  'cnt_words_unique' - количество уникальных слов\n",
        "10. 'unwords_words' - отношение количества уникальных слов к количеству слов\n",
        "11. 'median_word_length' - медианная длина слов\n",
        "12. 'mean_word_length' - средняя длина слова\n",
        "13. 'max_word_length' - максимальная длина слова\n",
        "14. 'words_symbols' - отношение количества слов к количеству символов\n",
        "15. 'words_dots' - отношение количества слов к количеству точек\n",
        "16. 'words_commas' - отношение количества слов к количеству запятых\n",
        "17. 'words_excls' - отношение количества слов к количеству восклицательных знаков\n",
        "18. 'words_questions' - отношение количества слов к количеству вопросительных знаков\n",
        "19. 'words_semicolons' - отношение количества слов к количеству точек с запятой\n",
        "20. 'words_colons' - отношение количества слов к количеству двоеточий\n",
        "21. 'words_dashs' - отношение количества слов к количеству тире\n",
        "22. 'words_aposts' - отношение количества слов к количеству апострофов\n",
        "23. 'words_ellipsis' - отношение количества слов к количеству многоточий\n",
        "24. 'words_quots' - отношение количества слов к количеству кавычек\n",
        "25. 'cnt_adv_freq' - словарь с количествами частотных наречий\n",
        "26. 'cnt_swadesh_freq' - словарь с количествами слов из списка Сводеша\n",
        "27. 'cnt_word_eng' - количество уникальных слов из словаря англ. языка\n",
        "28. 'prc_wrds_not_eng' - отношение количества английских слов к количеству слов\n",
        "29. 'uniq_word_cnt' - словарь с количествами уникальных слов\n",
        "30. 'cnt_punct_frq' - словарь с количествами знаков пунктуации\n",
        "31. 'lex_div' - (lexical_diversity) - лексическое разнообразие\n",
        "32. 'tfidf_keywords' - ключевые слова с максимальными TF-IDF значениями\n",
        "33. 'pos_frq' - словарь с количествами слов по частям речи\n",
        "34. 'pos_cnt' - количество уникальных частей речи\n",
        "35. 'ent_frq' - словарь с количествами слов именнованных сущностей\n",
        "36. 'ent_cnt' - количество уникальных именнованных сущностей\n",
        "37. 'uchars_frq' - словарь с количествами букв английского алфавита\n",
        "38. 'uchars_cnt' - количество уникальных букв английского алфавита\n",
        "39. 'fk_score' - показатель уровня читаемости текста по формуле Flesch-Kincaid"
      ],
      "metadata": {
        "id": "eQgDBaVuzLGX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Оставим только данные необходимые для обучения модели"
      ],
      "metadata": {
        "id": "vz-TpUVU0mdJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ytrain = df_train['author']\n",
        "ytest = df_test['author']"
      ],
      "metadata": {
        "id": "C-jpyAULzYIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7q0PwJpoyVeQ"
      },
      "outputs": [],
      "source": [
        "Xtrain = df_train.text\n",
        "Xtest = df_test.text\n",
        "del df_train, df_test"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Напишем функцию для подсчёта метрик классификации и составления отчёта"
      ],
      "metadata": {
        "id": "8U_BEQiM0xDm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "def calculate_multiclass_metrics(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Рассчитывает основные метрики для многоклассовой классификации.\n",
        "\n",
        "    :param y_true: Список или массив истинных значений классов.\n",
        "    :param y_pred: Список или массив предсказанных значений классов.\n",
        "    :return: Словарь с основными метриками.\n",
        "    \"\"\"\n",
        "\n",
        "    metrics = {\n",
        "        'accuracy': round(accuracy_score(y_true, y_pred), 4),\n",
        "        'precision_macro': round(precision_score(y_true, y_pred, average='macro'), 4),\n",
        "        'recall_macro': round(recall_score(y_true, y_pred, average='macro'), 4),\n",
        "        'f1_macro': round(f1_score(y_true, y_pred, average='macro'), 4),\n",
        "        'precision_micro': round(precision_score(y_true, y_pred, average='micro'), 4),\n",
        "        'recall_micro': round(recall_score(y_true, y_pred, average='micro'), 4),\n",
        "        'f1_micro': round(f1_score(y_true, y_pred, average='micro'), 4),\n",
        "    }\n",
        "\n",
        "    # Также можно вывести подробный отчет по каждому классу\n",
        "    report = classification_report(y_true, y_pred)\n",
        "    print(\"Classification Report:\\n\", report)\n",
        "\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "qOvhl_cTy2YF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Наилучший результат в проведённых эксперементах показала модель логистической регрессии, с использованием OneVsRestClassifier на текстах обработанных векторизатором Tfidf с униграммами и биграммами и отнормированные MaxAbsScaler. Весь код обучения модели был собран в pipeline и затем сохранён при помощи joblib."
      ],
      "metadata": {
        "id": "LgmtImrR3Q7x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "В результате данная модель показала такие метрики:<br>\n",
        " **accuracy**: 0.7255,<br>\n",
        " **precision_macro**: 0.6152,<br>\n",
        " **recall_macro**: 0.6727,<br>\n",
        " **f1_macro**: 0.6333,<br>\n",
        " **precision_micro**: 0.7255,<br>\n",
        " **recall_micro**: 0.7255,<br>\n",
        " **f1_micro**: 0.7255<br>"
      ],
      "metadata": {
        "id": "YT4_N8OU436R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import MaxAbsScaler\n",
        "import joblib\n",
        "\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
        "base_model = LogisticRegression(solver='liblinear')\n",
        "ovr = OneVsRestClassifier(base_model)\n",
        "scaler = MaxAbsScaler()\n",
        "pipeline = make_pipeline(vectorizer, scaler, ovr)\n",
        "\n",
        "pipeline.fit(train, ytrain)\n",
        "lr_pred = pipeline.predict(test)\n",
        "\n",
        "# joblib.dump(pipeline, 'pipeline.pkl')\n",
        "\n",
        "lr_pred_prob = pipeline.predict_proba(test)\n",
        "lr_probs = lr_pred_prob[:, 1]\n",
        "\n",
        "calculate_multiclass_metrics(ytest.tolist(), lr_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TZ6kqvEw8wz",
        "outputId": "892d4253-e15e-4213-f060-48a0d1a9fd7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "                               precision    recall  f1-score   support\n",
            "\n",
            "                       Aesop       0.50      1.00      0.67         1\n",
            "             Agatha_Christie       1.00      1.00      1.00         1\n",
            "             Alexandre_Dumas       1.00      1.00      1.00         1\n",
            "             Alphonse_Daudet       1.00      1.00      1.00         1\n",
            "               Anton_Chekhov       1.00      1.00      1.00         1\n",
            "                Aristophanes       1.00      1.00      1.00         1\n",
            "          Arthur_Conan_Doyle       1.00      1.00      1.00         1\n",
            "             Charles_Dickens       0.00      0.00      0.00         1\n",
            "             Dante_Alighieri       0.00      0.00      0.00         1\n",
            "             Edgar_Allan_Poe       1.00      1.00      1.00         1\n",
            "            Ernest_Hemingway       0.00      0.00      0.00         0\n",
            "          F_Scott_Fitzgerald       1.00      1.00      1.00         1\n",
            "                 Franz_Kafka       1.00      1.00      1.00         1\n",
            "          Fyodor_Dostoyevsky       1.00      1.00      1.00         1\n",
            "            Geoffrey_Chaucer       1.00      1.00      1.00         1\n",
            "               George_Orwell       0.00      0.00      0.00         1\n",
            "          Giovanni_Boccaccio       0.50      1.00      0.67         1\n",
            "            Graf_Leo_Tolstoy       0.00      0.00      0.00         1\n",
            "           Guy_De_Maupassant       0.00      0.00      0.00         1\n",
            "               H_P_Lovecraft       1.00      1.00      1.00         1\n",
            "     Hans_Christian_Andersen       0.50      1.00      0.67         1\n",
            "             Haruki_Murakami       1.00      1.00      1.00         1\n",
            "             Herman_Melville       1.00      1.00      1.00         1\n",
            "            Honore_De_Balzac       1.00      1.00      1.00         1\n",
            "                Isaac_Asimov       1.00      1.00      1.00         1\n",
            "               Italo_Calvino       1.00      1.00      1.00         1\n",
            "               Ivan_Turgenev       1.00      1.00      1.00         1\n",
            "               J_R_R_Tolkien       0.33      1.00      0.50         1\n",
            "                 Jack_London       1.00      1.00      1.00         1\n",
            "       James_Fenimore_Cooper       1.00      1.00      1.00         1\n",
            "                 James_Joyce       0.00      0.00      0.00         1\n",
            "                 Jane_Austen       1.00      1.00      1.00         1\n",
            "         Jean_De_La_Fontaine       0.00      0.00      0.00         1\n",
            "  Johann_Wolfgang_Von_Goethe       0.00      0.00      0.00         1\n",
            "                 Jules_Verne       0.50      1.00      0.67         1\n",
            "              Julio_Cortazar       0.00      0.00      0.00         0\n",
            "                  Lord_Byron       0.00      0.00      0.00         0\n",
            "                  Mark_Twain       1.00      1.00      1.00         1\n",
            "                 Maxim_Gorky       1.00      1.00      1.00         1\n",
            "                  Mayne_Reid       0.00      0.00      0.00         1\n",
            "Miguel_De_Cervantes_Saavedra       1.00      1.00      1.00         1\n",
            "                     Moliere       1.00      1.00      1.00         1\n",
            "                     O_Henry       1.00      1.00      1.00         1\n",
            "                 Oscar_Wilde       0.00      0.00      0.00         1\n",
            "      Publius_Vergilius_Maro       0.00      0.00      0.00         1\n",
            "      Robert_Louis_Stevenson       0.00      0.00      0.00         1\n",
            "                   Sophocles       1.00      1.00      1.00         1\n",
            "                    Stendhal       1.00      1.00      1.00         1\n",
            "                   T_S_Eliot       0.00      0.00      0.00         0\n",
            "                 Thomas_Mann       0.00      0.00      0.00         1\n",
            "                 Umberto_Eco       0.50      1.00      0.67         1\n",
            "                 Victor_Hugo       1.00      1.00      1.00         1\n",
            "              Virginia_Woolf       1.00      1.00      1.00         1\n",
            "            William_Faulkner       0.00      0.00      0.00         1\n",
            "         William_Shakespeare       1.00      1.00      1.00         1\n",
            "\n",
            "                    accuracy                           0.73        51\n",
            "                   macro avg       0.62      0.67      0.63        51\n",
            "                weighted avg       0.66      0.73      0.68        51\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.7255,\n",
              " 'precision_macro': 0.6152,\n",
              " 'recall_macro': 0.6727,\n",
              " 'f1_macro': 0.6333,\n",
              " 'precision_micro': 0.7255,\n",
              " 'recall_micro': 0.7255,\n",
              " 'f1_micro': 0.7255}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Попробуем написать код для тестирования работы модели. В ячейке ниже при отправке модели текста о Кольце Всевластия из произведения Толкиена, модель выводит 3-х наиболее вероятных на её взгляд авторов, и Толкиен находится на втором месте немного уступив в вероятности авторства Сент-Экзюпери :)"
      ],
      "metadata": {
        "id": "DM1CBKbZ5deF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "При загрузке pipeline, и замене текста в коде ячейки можно проводить свои собственные эксперименты с моделью."
      ],
      "metadata": {
        "id": "632riGo06KHO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "pipeline = joblib.load('pipeline.pkl')\n",
        "\n",
        "def predict_top_3_authors(text):\n",
        "    text_data = [text]\n",
        "    predicted_probs = pipeline.predict_proba(text_data)\n",
        "    top_3_indices = np.argsort(predicted_probs[0])[-3:][::-1]\n",
        "    top_3_probs = predicted_probs[0][top_3_indices]\n",
        "    top_3_authors = pipeline.named_steps['onevsrestclassifier'].classes_[top_3_indices]\n",
        "    for author, prob in zip(top_3_authors, top_3_probs):\n",
        "        print(f\"Author: {author}, Probability: {prob}\")\n",
        "\n",
        "example_text ='''\n",
        "One ring to rule them all, one ring to find them,\n",
        "One ring to bring them all and in the darkness bind them.'''\n",
        "predict_top_3_authors(example_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WmUx5haSfGE",
        "outputId": "1c49dbf0-29ea-4cf4-ea38-6c432456205a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Author: Antoine_De_Saint_Exupery, Probability: 0.01396337039015265\n",
            "Author: J_R_R_Tolkien, Probability: 0.013169534324720733\n",
            "Author: Aesop, Probability: 0.012547013893284076\n"
          ]
        }
      ]
    }
  ]
}