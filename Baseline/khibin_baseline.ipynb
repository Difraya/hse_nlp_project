{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10130950,"sourceType":"datasetVersion","datasetId":6252383},{"sourceId":10166236,"sourceType":"datasetVersion","datasetId":6278014}],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Baseline решение классификации авторов по тексту\n\n## План работы\n\n1. **Предобработка данных** : очистка текста, подготовка датасета.\n\n\n\n2. **Минимальный baseline** : случайное предсказание/предсказание самого частого класса, чтобы потом ориентироваться на эти значения при оценке других подходов.\n\n\n\n3. **Использование эвристик** :\n    - **Lexicon-based**: предсказание с использованием словарей, например, для тональности и токсичности;\n    - **Rule-based**: предсказание с использованием различных паттернов: ключевые слова, регулярные выражения, счетчики положительных/отрицательных слов, длина текста и среднего количества слов в предложении, формулы для оценки сложности текста (например, Flesch-Kincaid), детекция простых шаблонов и специфических фраз, определение разнообразия словарного запаса и структуры текста и т.д.\n\n\n\n4. **Статистическе подходы и ML** :\n   - **BoW** или **TF-IDF** вместе с линейными классификаторами (**Logistic Regression** / **SVM**);\n   - **N-gram'ы** и **Naive Bayes**: учет последовательности слов.\n\n\n\n5. **Создание эмбеддингов и обучение простой модели**:\n    - **Word2Vec** / **GloVe** вместе с  **LogReg** / **Linear Classifier** / **SVM** \n\n\n\n6. **Создание ансамблей** (комбинации простых моделей для повышения точности).","metadata":{}},{"cell_type":"markdown","source":"## Импорт библиотек","metadata":{}},{"cell_type":"code","source":"!pip install langdetect\n!pip install pymorphy2\n!pip install gensim\n!unzip /usr/share/nltk_data/corpora/wordnet.zip -d /usr/share/nltk_data/corpora/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T17:31:09.544690Z","iopub.execute_input":"2024-12-11T17:31:09.545733Z","iopub.status.idle":"2024-12-11T17:31:55.557179Z","shell.execute_reply.started":"2024-12-11T17:31:09.545673Z","shell.execute_reply":"2024-12-11T17:31:55.555844Z"}},"outputs":[{"name":"stdout","text":"Collecting langdetect\n  Downloading langdetect-1.0.9.tar.gz (981 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from langdetect) (1.16.0)\nBuilding wheels for collected packages: langdetect\n  Building wheel for langdetect (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993227 sha256=c9f3bc4b323038f80ef39a3d0ba43bb1df502287d78c95d16599b85d2a1f54b8\n  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\nSuccessfully built langdetect\nInstalling collected packages: langdetect\nSuccessfully installed langdetect-1.0.9\nCollecting pymorphy2\n  Downloading pymorphy2-0.9.1-py3-none-any.whl.metadata (3.6 kB)\nCollecting dawg-python>=0.7.1 (from pymorphy2)\n  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl.metadata (7.0 kB)\nCollecting pymorphy2-dicts-ru<3.0,>=2.4 (from pymorphy2)\n  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl.metadata (2.1 kB)\nRequirement already satisfied: docopt>=0.6 in /opt/conda/lib/python3.10/site-packages (from pymorphy2) (0.6.2)\nDownloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\nDownloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hInstalling collected packages: pymorphy2-dicts-ru, dawg-python, pymorphy2\nSuccessfully installed dawg-python-0.7.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\nRequirement already satisfied: gensim in /opt/conda/lib/python3.10/site-packages (4.3.3)\nRequirement already satisfied: numpy<2.0,>=1.18.5 in /opt/conda/lib/python3.10/site-packages (from gensim) (1.26.4)\nCollecting scipy<1.14.0,>=1.7.0 (from gensim)\n  Downloading scipy-1.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.10/site-packages (from gensim) (7.0.4)\nRequirement already satisfied: wrapt in /opt/conda/lib/python3.10/site-packages (from smart-open>=1.8.1->gensim) (1.16.0)\nDownloading scipy-1.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: scipy\n  Attempting uninstall: scipy\n    Found existing installation: scipy 1.14.1\n    Uninstalling scipy-1.14.1:\n      Successfully uninstalled scipy-1.14.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncesium 0.12.3 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nlibpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmlxtend 0.23.3 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\nplotnine 0.14.3 requires matplotlib>=3.8.0, but you have matplotlib 3.7.5 which is incompatible.\ntsfresh 0.20.3 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed scipy-1.13.1\nArchive:  /usr/share/nltk_data/corpora/wordnet.zip\n   creating: /usr/share/nltk_data/corpora/wordnet/\n  inflating: /usr/share/nltk_data/corpora/wordnet/lexnames  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.verb  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.adv  \n  inflating: /usr/share/nltk_data/corpora/wordnet/adv.exc  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.verb  \n  inflating: /usr/share/nltk_data/corpora/wordnet/cntlist.rev  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.adj  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.adj  \n  inflating: /usr/share/nltk_data/corpora/wordnet/LICENSE  \n  inflating: /usr/share/nltk_data/corpora/wordnet/citation.bib  \n  inflating: /usr/share/nltk_data/corpora/wordnet/noun.exc  \n  inflating: /usr/share/nltk_data/corpora/wordnet/verb.exc  \n  inflating: /usr/share/nltk_data/corpora/wordnet/README  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.sense  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.noun  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.adv  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.noun  \n  inflating: /usr/share/nltk_data/corpora/wordnet/adj.exc  \n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom bs4 import BeautifulSoup\nimport re\nimport string\n\nimport nltk\nimport spacy\nfrom nltk import tokenize\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\n\n# Убедитесь, что необходимые ресурсы загружены\nnltk.download('punkt')\nnltk.download('stopwords')\nnltk.download('wordnet')\nnltk.download('corpora')\nnltk.download('wordnet')\n\nfrom langdetect import detect\n\nfrom collections import Counter\n\nfrom sklearn.dummy import DummyClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import MultinomialNB\n\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom gensim.models import Word2Vec\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.base import BaseEstimator, TransformerMixin\n\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n\nsns.set_theme(rc={'figure.figsize':(15, 7)})\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-11T17:31:55.560067Z","iopub.execute_input":"2024-12-11T17:31:55.560569Z","iopub.status.idle":"2024-12-11T17:32:20.228302Z","shell.execute_reply.started":"2024-12-11T17:31:55.560512Z","shell.execute_reply":"2024-12-11T17:32:20.227055Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Error loading corpora: Package 'corpora' not found in\n[nltk_data]     index\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n/kaggle/input/glove-text/glove.6B.100d.txt\n/kaggle/input/top-100-authors-preprocessed-train-test/top100_preprocessed_test.pq\n/kaggle/input/top-100-authors-preprocessed-train-test/top100_preprocessed.pq\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"RANDOM_STATE = 17","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T17:32:20.229708Z","iopub.execute_input":"2024-12-11T17:32:20.230390Z","iopub.status.idle":"2024-12-11T17:32:20.235323Z","shell.execute_reply.started":"2024-12-11T17:32:20.230353Z","shell.execute_reply":"2024-12-11T17:32:20.234165Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"## Загрузка данных","metadata":{}},{"cell_type":"code","source":"# Функция для краткого описания данных\ndef data_info(df):\n    print(f'Количество строк - {df.shape[0]}\\n', f'Количество столбцов - {df.shape[1]}', sep='')\n    \n    display(df.head(3))\n    return df.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T17:32:20.237935Z","iopub.execute_input":"2024-12-11T17:32:20.238309Z","iopub.status.idle":"2024-12-11T17:32:20.368696Z","shell.execute_reply.started":"2024-12-11T17:32:20.238277Z","shell.execute_reply":"2024-12-11T17:32:20.367628Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"data_train = pd.read_parquet('/kaggle/input/top-100-authors-preprocessed-train-test/top100_preprocessed.pq')\ndata_test = pd.read_parquet('/kaggle/input/top-100-authors-preprocessed-train-test/top100_preprocessed_test.pq')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T17:32:20.370021Z","iopub.execute_input":"2024-12-11T17:32:20.370437Z","iopub.status.idle":"2024-12-11T17:34:47.303458Z","shell.execute_reply.started":"2024-12-11T17:32:20.370395Z","shell.execute_reply":"2024-12-11T17:34:47.302282Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"data_info(data_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T17:34:47.305037Z","iopub.execute_input":"2024-12-11T17:34:47.305380Z","iopub.status.idle":"2024-12-11T17:34:47.421037Z","shell.execute_reply.started":"2024-12-11T17:34:47.305346Z","shell.execute_reply":"2024-12-11T17:34:47.419744Z"}},"outputs":[{"name":"stdout","text":"Количество строк - 408\nКоличество столбцов - 42\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"             author author_sn                           title  \\\n0  Geoffrey_Chaucer   Chaucer            The_Canterbury_Tales   \n1       Umberto_Eco       Eco  From_The_Tree_To_The_Labyrinth   \n2       Victor_Hugo      Hugo                  Les_Misérables   \n\n                                                text  \\\n0   THE CANTERBURY TALES And other Poems of GEOFF...   \n1   FROM THE TREE TO THE LABYRINTH FROM THE TREE ...   \n2   LES MISÉRABLES By Victor Hugo Translated by I...   \n\n                                         FileName  is_gutenberg  text_len  \\\n0       Geoffrey_Chaucer-The_Canterbury_Tales.txt             0   1650684   \n1  Umberto_Eco-From_the_Tree_to_the_Labyrinth.txt             0   1533277   \n2                  Victor_Hugo-Les_Misérables.txt             1   3304624   \n\n   text_len2  words_cnt  words_symbols  ...  has_html  \\\n0    1517228     279354       0.184121  ...         1   \n1    1527975     249969       0.163595  ...         0   \n2    3210219     565614       0.176192  ...         0   \n\n                                        text_cleaned  \\\n0  canterbury tales poems geoffrey chaucer edited...   \n1  tree labyrinth tree labyrinth historical studi...   \n2  les mis rables victor hugo translated isabel f...   \n\n                                  text_cleaned_words  \\\n0  [canterbury, tales, poems, geoffrey, chaucer, ...   \n1  [tree, labyrinth, tree, labyrinth, historical,...   \n2  [les, mis, rables, victor, hugo, translated, i...   \n\n                          text_cleaned_lemmatization   fk_score  \\\n0  canterbury tale poem geoffrey chaucer edited p...  61.968180   \n1  tree labyrinth tree labyrinth historical study...  17.781446   \n2  le mi rables victor hugo translated isabel f h...  41.217732   \n\n   lexical_diversity  average_sentence_length  sentence_count  \\\n0           0.127333                13.579430           10569   \n1           0.153241                14.392021            9701   \n2           0.088120                 9.140349           29961   \n\n   average_word_length  syllable_count  \n0             8.670947          222379  \n1             9.125995          287891  \n2             9.656992          506079  \n\n[3 rows x 42 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>author</th>\n      <th>author_sn</th>\n      <th>title</th>\n      <th>text</th>\n      <th>FileName</th>\n      <th>is_gutenberg</th>\n      <th>text_len</th>\n      <th>text_len2</th>\n      <th>words_cnt</th>\n      <th>words_symbols</th>\n      <th>...</th>\n      <th>has_html</th>\n      <th>text_cleaned</th>\n      <th>text_cleaned_words</th>\n      <th>text_cleaned_lemmatization</th>\n      <th>fk_score</th>\n      <th>lexical_diversity</th>\n      <th>average_sentence_length</th>\n      <th>sentence_count</th>\n      <th>average_word_length</th>\n      <th>syllable_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Geoffrey_Chaucer</td>\n      <td>Chaucer</td>\n      <td>The_Canterbury_Tales</td>\n      <td>THE CANTERBURY TALES And other Poems of GEOFF...</td>\n      <td>Geoffrey_Chaucer-The_Canterbury_Tales.txt</td>\n      <td>0</td>\n      <td>1650684</td>\n      <td>1517228</td>\n      <td>279354</td>\n      <td>0.184121</td>\n      <td>...</td>\n      <td>1</td>\n      <td>canterbury tales poems geoffrey chaucer edited...</td>\n      <td>[canterbury, tales, poems, geoffrey, chaucer, ...</td>\n      <td>canterbury tale poem geoffrey chaucer edited p...</td>\n      <td>61.968180</td>\n      <td>0.127333</td>\n      <td>13.579430</td>\n      <td>10569</td>\n      <td>8.670947</td>\n      <td>222379</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Umberto_Eco</td>\n      <td>Eco</td>\n      <td>From_The_Tree_To_The_Labyrinth</td>\n      <td>FROM THE TREE TO THE LABYRINTH FROM THE TREE ...</td>\n      <td>Umberto_Eco-From_the_Tree_to_the_Labyrinth.txt</td>\n      <td>0</td>\n      <td>1533277</td>\n      <td>1527975</td>\n      <td>249969</td>\n      <td>0.163595</td>\n      <td>...</td>\n      <td>0</td>\n      <td>tree labyrinth tree labyrinth historical studi...</td>\n      <td>[tree, labyrinth, tree, labyrinth, historical,...</td>\n      <td>tree labyrinth tree labyrinth historical study...</td>\n      <td>17.781446</td>\n      <td>0.153241</td>\n      <td>14.392021</td>\n      <td>9701</td>\n      <td>9.125995</td>\n      <td>287891</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Victor_Hugo</td>\n      <td>Hugo</td>\n      <td>Les_Misérables</td>\n      <td>LES MISÉRABLES By Victor Hugo Translated by I...</td>\n      <td>Victor_Hugo-Les_Misérables.txt</td>\n      <td>1</td>\n      <td>3304624</td>\n      <td>3210219</td>\n      <td>565614</td>\n      <td>0.176192</td>\n      <td>...</td>\n      <td>0</td>\n      <td>les mis rables victor hugo translated isabel f...</td>\n      <td>[les, mis, rables, victor, hugo, translated, i...</td>\n      <td>le mi rables victor hugo translated isabel f h...</td>\n      <td>41.217732</td>\n      <td>0.088120</td>\n      <td>9.140349</td>\n      <td>29961</td>\n      <td>9.656992</td>\n      <td>506079</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows × 42 columns</p>\n</div>"},"metadata":{}},{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nIndex: 408 entries, 0 to 408\nData columns (total 42 columns):\n #   Column                      Non-Null Count  Dtype  \n---  ------                      --------------  -----  \n 0   author                      408 non-null    object \n 1   author_sn                   408 non-null    object \n 2   title                       408 non-null    object \n 3   text                        408 non-null    object \n 4   FileName                    408 non-null    object \n 5   is_gutenberg                408 non-null    int64  \n 6   text_len                    408 non-null    int64  \n 7   text_len2                   408 non-null    int64  \n 8   words_cnt                   408 non-null    int64  \n 9   words_symbols               408 non-null    float64\n 10  words_dots                  408 non-null    float64\n 11  words_commas                408 non-null    float64\n 12  words_excls                 408 non-null    float64\n 13  words_questions             408 non-null    float64\n 14  words_semicolons            408 non-null    float64\n 15  words_colons                408 non-null    float64\n 16  words_dashs                 408 non-null    float64\n 17  words_aposts                408 non-null    float64\n 18  words_ellipsis              408 non-null    float64\n 19  words_quots                 408 non-null    float64\n 20  median_word_length          408 non-null    float64\n 21  max_word_length             408 non-null    int64  \n 22  mean_word_length            408 non-null    float64\n 23  cnt_adv_freq                408 non-null    object \n 24  cnt_swadesh_freq            408 non-null    object \n 25  uniq_word_cnt               408 non-null    object \n 26  cnt_words_unique            408 non-null    int64  \n 27  unwords_words               408 non-null    float64\n 28  cnt_word_eng                408 non-null    int64  \n 29  prc_wrds_not_eng            408 non-null    float64\n 30  a_books_cnt                 408 non-null    int64  \n 31  text_language               408 non-null    object \n 32  has_html                    408 non-null    int64  \n 33  text_cleaned                408 non-null    object \n 34  text_cleaned_words          408 non-null    object \n 35  text_cleaned_lemmatization  408 non-null    object \n 36  fk_score                    408 non-null    float64\n 37  lexical_diversity           408 non-null    float64\n 38  average_sentence_length     408 non-null    float64\n 39  sentence_count              408 non-null    int64  \n 40  average_word_length         408 non-null    float64\n 41  syllable_count              408 non-null    int64  \ndtypes: float64(19), int64(11), object(12)\nmemory usage: 137.1+ KB\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"data_info(data_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T17:34:47.422682Z","iopub.execute_input":"2024-12-11T17:34:47.423184Z","iopub.status.idle":"2024-12-11T17:34:47.500828Z","shell.execute_reply.started":"2024-12-11T17:34:47.423136Z","shell.execute_reply":"2024-12-11T17:34:47.499594Z"}},"outputs":[{"name":"stdout","text":"Количество строк - 51\nКоличество столбцов - 16\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"               author author_sn                         title  \\\n5582            Aesop     Aesop                Aesop's_Fables   \n3938  Agatha_Christie  Christie           Poirot_Investigates   \n3881  Alexandre_Dumas     Dumas  Celebrated_Crimes_(complete)   \n\n                                                   text  \\\n5582  \\r\\n\\r\\n[Illustration]\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nThe ...   \n3938  \\r\\n\\r\\n\\r\\n\\r\\nProduced by an anonymous Proje...   \n3881  \\n\\n\\n\\n\\nProduced by David Widger.\\n\\n\\n\\n\\n\\...   \n\n                                              FileName  is_gutenberg  \\\n5582                          Aesop-Aesop's_Fables.txt             1   \n3938           Agatha_Christie-Poirot_Investigates.txt             1   \n3881  Alexandre_Dumas-Celebrated_Crimes_(complete).txt             1   \n\n      has_html                                       text_cleaned  \\\n5582         0  illustration fables aesop selected told anew h...   \n3938         0  produced anonymous project gutenberg volunteer...   \n3881         1  produced david widger celebrated crimes comple...   \n\n                                     text_cleaned_words  \\\n5582  [illustration, fables, aesop, selected, told, ...   \n3938  [produced, anonymous, project, gutenberg, volu...   \n3881  [produced, david, widger, celebrated, crimes, ...   \n\n                             text_cleaned_lemmatization   fk_score  \\\n5582  illustration fable aesop selected told anew hi...  60.888825   \n3938  produced anonymous project gutenberg volunteer...  47.552857   \n3881  produced david widger celebrated crime complet...  31.969128   \n\n      lexical_diversity  average_sentence_length  sentence_count  \\\n5582           0.355881                12.258803             568   \n3938           0.225270                 7.341569            3481   \n3881           0.074072                13.577580           21855   \n\n      average_word_length  syllable_count  \n5582             9.037197           10988  \n3938             9.462748           45865  \n3881             9.773315          565011  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>author</th>\n      <th>author_sn</th>\n      <th>title</th>\n      <th>text</th>\n      <th>FileName</th>\n      <th>is_gutenberg</th>\n      <th>has_html</th>\n      <th>text_cleaned</th>\n      <th>text_cleaned_words</th>\n      <th>text_cleaned_lemmatization</th>\n      <th>fk_score</th>\n      <th>lexical_diversity</th>\n      <th>average_sentence_length</th>\n      <th>sentence_count</th>\n      <th>average_word_length</th>\n      <th>syllable_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5582</th>\n      <td>Aesop</td>\n      <td>Aesop</td>\n      <td>Aesop's_Fables</td>\n      <td>\\r\\n\\r\\n[Illustration]\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nThe ...</td>\n      <td>Aesop-Aesop's_Fables.txt</td>\n      <td>1</td>\n      <td>0</td>\n      <td>illustration fables aesop selected told anew h...</td>\n      <td>[illustration, fables, aesop, selected, told, ...</td>\n      <td>illustration fable aesop selected told anew hi...</td>\n      <td>60.888825</td>\n      <td>0.355881</td>\n      <td>12.258803</td>\n      <td>568</td>\n      <td>9.037197</td>\n      <td>10988</td>\n    </tr>\n    <tr>\n      <th>3938</th>\n      <td>Agatha_Christie</td>\n      <td>Christie</td>\n      <td>Poirot_Investigates</td>\n      <td>\\r\\n\\r\\n\\r\\n\\r\\nProduced by an anonymous Proje...</td>\n      <td>Agatha_Christie-Poirot_Investigates.txt</td>\n      <td>1</td>\n      <td>0</td>\n      <td>produced anonymous project gutenberg volunteer...</td>\n      <td>[produced, anonymous, project, gutenberg, volu...</td>\n      <td>produced anonymous project gutenberg volunteer...</td>\n      <td>47.552857</td>\n      <td>0.225270</td>\n      <td>7.341569</td>\n      <td>3481</td>\n      <td>9.462748</td>\n      <td>45865</td>\n    </tr>\n    <tr>\n      <th>3881</th>\n      <td>Alexandre_Dumas</td>\n      <td>Dumas</td>\n      <td>Celebrated_Crimes_(complete)</td>\n      <td>\\n\\n\\n\\n\\nProduced by David Widger.\\n\\n\\n\\n\\n\\...</td>\n      <td>Alexandre_Dumas-Celebrated_Crimes_(complete).txt</td>\n      <td>1</td>\n      <td>1</td>\n      <td>produced david widger celebrated crimes comple...</td>\n      <td>[produced, david, widger, celebrated, crimes, ...</td>\n      <td>produced david widger celebrated crime complet...</td>\n      <td>31.969128</td>\n      <td>0.074072</td>\n      <td>13.577580</td>\n      <td>21855</td>\n      <td>9.773315</td>\n      <td>565011</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nIndex: 51 entries, 5582 to 3319\nData columns (total 16 columns):\n #   Column                      Non-Null Count  Dtype  \n---  ------                      --------------  -----  \n 0   author                      51 non-null     object \n 1   author_sn                   51 non-null     object \n 2   title                       51 non-null     object \n 3   text                        51 non-null     object \n 4   FileName                    51 non-null     object \n 5   is_gutenberg                51 non-null     int64  \n 6   has_html                    51 non-null     int64  \n 7   text_cleaned                51 non-null     object \n 8   text_cleaned_words          51 non-null     object \n 9   text_cleaned_lemmatization  51 non-null     object \n 10  fk_score                    51 non-null     float64\n 11  lexical_diversity           51 non-null     float64\n 12  average_sentence_length     51 non-null     float64\n 13  sentence_count              51 non-null     int64  \n 14  average_word_length         51 non-null     float64\n 15  syllable_count              51 non-null     int64  \ndtypes: float64(4), int64(4), object(8)\nmemory usage: 6.8+ KB\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Убедимся, что в тренировочных данных нет тестовых\ntest_titles = list(data_test['title'].unique())\n\ndata_train = data_train[~data_train.title.isin(test_titles)]\ndata_train.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T17:34:47.502246Z","iopub.execute_input":"2024-12-11T17:34:47.502573Z","iopub.status.idle":"2024-12-11T17:34:47.685424Z","shell.execute_reply.started":"2024-12-11T17:34:47.502539Z","shell.execute_reply":"2024-12-11T17:34:47.684173Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"(363, 42)"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"# Проверим, сколько авторов из тренировочных и тестовых данных совпадает\nlen(set(data_test['author']) & set(data_train['author'])) / len(set(data_test['author']))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T17:34:47.686877Z","iopub.execute_input":"2024-12-11T17:34:47.687205Z","iopub.status.idle":"2024-12-11T17:34:47.700224Z","shell.execute_reply.started":"2024-12-11T17:34:47.687174Z","shell.execute_reply":"2024-12-11T17:34:47.699264Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"0.9607843137254902"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"# Нужно для функций дальше\ndata_train['text_cleaned_words'] = data_train['text_cleaned_words'].apply(lambda x: list(x))\ndata_test['text_cleaned_words'] = data_test['text_cleaned_words'].apply(lambda x: list(x))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T17:34:47.703960Z","iopub.execute_input":"2024-12-11T17:34:47.704302Z","iopub.status.idle":"2024-12-11T17:34:48.325979Z","shell.execute_reply.started":"2024-12-11T17:34:47.704269Z","shell.execute_reply":"2024-12-11T17:34:48.324805Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def metrics(y_pred, y_test, y_pred_probas=None):    \n    # Для многоклассовой классификации\n    accuracy = accuracy_score(y_test, y_pred)\n    precision_macro = precision_score(y_test, y_pred, average='macro')\n    precision_micro = precision_score(y_test, y_pred, average='micro')\n    recall_macro = recall_score(y_test, y_pred, average='macro')\n    recall_micro = recall_score(y_test, y_pred, average='micro')\n    f1_macro = f1_score(y_test, y_pred, average='macro')\n    f1_micro = f1_score(y_test, y_pred, average='micro')\n    \n\n    if y_pred_probas:\n        roc_auc = roc_auc_score(y_test, y_pred_probas, multi_class='ovr')\n    else:\n        roc_auc = None\n\n\n    # Создание DataFrame с метриками\n    metrics = {\n        'Metric': ['Accuracy', 'Precision (Macro)', 'Precision (Micro)', \n                   'Recall (Macro)', 'Recall (Micro)', \n                   'F1 Score (Macro)', 'F1 Score (Micro)', 'ROC AUC'],\n        'Score': [accuracy, precision_macro, precision_micro, \n                  recall_macro, recall_micro, \n                  f1_macro, f1_micro, roc_auc]\n    }\n    \n    return pd.DataFrame(metrics)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T17:34:48.327392Z","iopub.execute_input":"2024-12-11T17:34:48.327822Z","iopub.status.idle":"2024-12-11T17:34:48.335907Z","shell.execute_reply.started":"2024-12-11T17:34:48.327753Z","shell.execute_reply":"2024-12-11T17:34:48.334676Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"columns_to_drop = list(set(data_train.columns) - set(data_test.columns)) + ['author_sn', 'title', 'FileName', 'is_gutenberg', 'has_html']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T17:34:48.337484Z","iopub.execute_input":"2024-12-11T17:34:48.337960Z","iopub.status.idle":"2024-12-11T17:34:48.355375Z","shell.execute_reply.started":"2024-12-11T17:34:48.337910Z","shell.execute_reply":"2024-12-11T17:34:48.354173Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# Выберем только нужные признаки\ndata_train = data_train.drop(columns_to_drop, axis=1)\ndata_test = data_test.drop(['author_sn', 'title', 'FileName', 'is_gutenberg', 'has_html'], axis=1)\n\n# Разделим данные \nX_train, y_train = data_train.drop(['author'], axis=1), data_train['author']\nX_test, y_test = data_test.drop(['author'], axis=1), data_test['author']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T17:34:48.356759Z","iopub.execute_input":"2024-12-11T17:34:48.357149Z","iopub.status.idle":"2024-12-11T17:34:50.058638Z","shell.execute_reply.started":"2024-12-11T17:34:48.357117Z","shell.execute_reply":"2024-12-11T17:34:50.057414Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"print(f'Размерность тренировочных данных: {X_train.shape}, {y_train.shape}')\nprint(f'Размерность тестовых данных: {X_test.shape}, {y_test.shape}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T17:34:50.060101Z","iopub.execute_input":"2024-12-11T17:34:50.060484Z","iopub.status.idle":"2024-12-11T17:34:50.073005Z","shell.execute_reply.started":"2024-12-11T17:34:50.060448Z","shell.execute_reply":"2024-12-11T17:34:50.071813Z"}},"outputs":[{"name":"stdout","text":"Размерность тренировочных данных: (363, 10), (363,)\nРазмерность тестовых данных: (51, 10), (51,)\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"Предобработка уже была выполнена на предыдущем шаге, поэтому, чтобы не тратить время, я не стал копировать код с предобработкой в этот датасет. Данные уже предобработаны: приведены в нижний регистр, очищены от пунктуации, очищены от стопслов, разбиты на токены и лемматизированы. Далее идет работа с моделями.","metadata":{}},{"cell_type":"markdown","source":"## DummyClassifier - определяем baseline","metadata":{}},{"cell_type":"code","source":"dummy_classifier = DummyClassifier(strategy='most_frequent', random_state=RANDOM_STATE)\ndummy_classifier.fit(X_train, y_train)\ny_pred = dummy_classifier.predict(X_test)\n\nbaseline_metrics = metrics(y_pred, y_test)\nbaseline_metrics","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T17:34:50.074459Z","iopub.execute_input":"2024-12-11T17:34:50.074885Z","iopub.status.idle":"2024-12-11T17:34:50.109343Z","shell.execute_reply.started":"2024-12-11T17:34:50.074847Z","shell.execute_reply":"2024-12-11T17:34:50.108242Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"              Metric     Score\n0           Accuracy  0.019608\n1  Precision (Macro)  0.000384\n2  Precision (Micro)  0.019608\n3     Recall (Macro)  0.019608\n4     Recall (Micro)  0.019608\n5   F1 Score (Macro)  0.000754\n6   F1 Score (Micro)  0.019608\n7            ROC AUC       NaN","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Metric</th>\n      <th>Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Accuracy</td>\n      <td>0.019608</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Precision (Macro)</td>\n      <td>0.000384</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Precision (Micro)</td>\n      <td>0.019608</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Recall (Macro)</td>\n      <td>0.019608</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Recall (Micro)</td>\n      <td>0.019608</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>F1 Score (Macro)</td>\n      <td>0.000754</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>F1 Score (Micro)</td>\n      <td>0.019608</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>ROC AUC</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":15},{"cell_type":"markdown","source":"## Эвристики","metadata":{}},{"cell_type":"markdown","source":"### Lexicon-based","metadata":{}},{"cell_type":"code","source":"# Функция для подсчета самых распространенных слов у автора\ndef author_top_words(data, col_author='author', col_words='text_cleaned_words', n_top=50):\n    author_words_count = data.groupby([col_author])[col_words].sum().to_frame()\\\n                             .apply(lambda x: Counter(x[col_words]), axis=1).to_frame()\\\n                             .apply(lambda row: sorted(row[0].items(), key=lambda x: x[1], reverse=True)[:n_top], axis=1).to_frame()\n\n    author_words_count = author_words_count[0].apply(lambda x: dict(x).keys()).to_frame().reset_index()\n    author_words_count.columns = ['author', \"top_words\"]\n    \n    return author_words_count","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T17:34:50.111031Z","iopub.execute_input":"2024-12-11T17:34:50.111484Z","iopub.status.idle":"2024-12-11T17:34:50.118974Z","shell.execute_reply.started":"2024-12-11T17:34:50.111439Z","shell.execute_reply":"2024-12-11T17:34:50.117876Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"Для создания **lexicon-based** эвристики для определения автора текста для каждого автора создается набор наиболее часто используемых/уникальных слов. Затем текст с неизвестным автором сравнивается с наборами слов, после чего определяется наиболее вероятный автор на основе частоты появления их лексиконов в тексте. То есть нужно подсчитать, сколько слов каждого автора встречается в тексте, и определить автора по максимальному количеству совпадений.ений.","metadata":{}},{"cell_type":"code","source":"def lexicon_based_classifier(text, author_lexicons):\n    word_count = Counter(text.split())\n    authors = author_lexicons['author']\n    scores = dict.fromkeys(authors, 0)\n\n    for author in authors:\n        for word in author_lexicons.set_index('author').loc[author]['top_words']:\n            scores[author] += word_count[word]\n        \n    return max(scores, key=scores.get)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T17:34:50.120375Z","iopub.execute_input":"2024-12-11T17:34:50.120704Z","iopub.status.idle":"2024-12-11T17:34:50.134815Z","shell.execute_reply.started":"2024-12-11T17:34:50.120674Z","shell.execute_reply":"2024-12-11T17:34:50.133653Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"Пример предсказания текста Достоевского на тренировочных данных.","metadata":{}},{"cell_type":"code","source":"author_lexicons = author_top_words(data_train, n_top=50)\nauthor_lexicons\nlexicon_based_classifier(X_train.loc[201]['text_cleaned'], author_lexicons=author_lexicons)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T17:34:50.136583Z","iopub.execute_input":"2024-12-11T17:34:50.137026Z","iopub.status.idle":"2024-12-11T17:34:53.357025Z","shell.execute_reply.started":"2024-12-11T17:34:50.136979Z","shell.execute_reply":"2024-12-11T17:34:53.355666Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"'Fyodor_Dostoyevsky'"},"metadata":{}}],"execution_count":18},{"cell_type":"markdown","source":"Сделаем предсказания для каждого автора на тестовых данных и рассчитаем метрики.","metadata":{}},{"cell_type":"code","source":"y_pred = X_test['text_cleaned'].apply(lambda x: lexicon_based_classifier(x, author_lexicons))\n\n# Расчитываем метрики\nlexicon_based_metrics = metrics(y_pred, y_test)\nlexicon_based_metrics","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T17:34:53.358592Z","iopub.execute_input":"2024-12-11T17:34:53.358955Z","iopub.status.idle":"2024-12-11T17:34:56.446672Z","shell.execute_reply.started":"2024-12-11T17:34:53.358921Z","shell.execute_reply":"2024-12-11T17:34:56.445552Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"              Metric     Score\n0           Accuracy  0.568627\n1  Precision (Macro)  0.450292\n2  Precision (Micro)  0.568627\n3     Recall (Macro)  0.508772\n4     Recall (Micro)  0.568627\n5   F1 Score (Macro)  0.467836\n6   F1 Score (Micro)  0.568627\n7            ROC AUC       NaN","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Metric</th>\n      <th>Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Accuracy</td>\n      <td>0.568627</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Precision (Macro)</td>\n      <td>0.450292</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Precision (Micro)</td>\n      <td>0.568627</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Recall (Macro)</td>\n      <td>0.508772</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Recall (Micro)</td>\n      <td>0.568627</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>F1 Score (Macro)</td>\n      <td>0.467836</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>F1 Score (Micro)</td>\n      <td>0.568627</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>ROC AUC</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":19},{"cell_type":"markdown","source":"### Rule-based подход\n\nRule-based: предсказание с использованием различных паттернов: ключевые слова, регулярные выражения, счетчики положительных/отрицательных слов, длина текста и среднего количества слов в предложении, формулы для оценки сложности текста (например, Flesch-Kincaid), детекция простых шаблонов и специфических фраз, определение разнообразия словарного запаса и структуры текста и т.д.","metadata":{}},{"cell_type":"code","source":"# Функция для подсчета слогов в слове\ndef nsyllables(word):\n    word = word.lower()\n    syllable_count = 0\n    vowels = \"aeiouy\"\n    \n    if word[0] in vowels:\n        syllable_count += 1\n        \n    for i in range(1, len(word)):\n        if word[i] in vowels and word[i - 1] not in vowels:\n            syllable_count += 1\n        \n    if word.endswith(\"e\"):\n        syllable_count -= 1\n    if syllable_count == 0:\n            yllable_count = 1\n    \n    return syllable_count","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T17:34:56.447930Z","iopub.execute_input":"2024-12-11T17:34:56.448227Z","iopub.status.idle":"2024-12-11T17:34:56.455002Z","shell.execute_reply.started":"2024-12-11T17:34:56.448198Z","shell.execute_reply":"2024-12-11T17:34:56.453752Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# Функция для анализа текста. \ndef analyze_text(text, text_cleaned):\n    # Выделение предложений из текста\n    sentences = nltk.sent_tokenize(text)\n    # Выделение слов из текста \n    words = nltk.word_tokenize(text_cleaned)\n    word_count = len(words)\n    sentence_count = len(sentences)\n    average_sentence_length = word_count / sentence_count if sentence_count > 0 else 0\n    syllable_count = sum([nsyllables(word) for word in words])\n    \n    # Оценка сложности текста\n    if len(sentences) == 0 or len(words) == 0:\n        return 0\n    else:\n        fk_score = 206.835 - 1.015 * (word_count / sentence_count) - 84.6 * (syllable_count / word_count)   # calculate_flesch_kincaid(text)\n\n    return fk_score, average_sentence_length","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T17:34:56.456447Z","iopub.execute_input":"2024-12-11T17:34:56.456835Z","iopub.status.idle":"2024-12-11T17:34:56.477682Z","shell.execute_reply.started":"2024-12-11T17:34:56.456763Z","shell.execute_reply":"2024-12-11T17:34:56.476443Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"author_profiles = data_train.groupby('author')[['fk_score', 'average_sentence_length']].mean().reset_index()\nauthor_profiles.head(3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T17:34:56.479070Z","iopub.execute_input":"2024-12-11T17:34:56.479426Z","iopub.status.idle":"2024-12-11T17:34:56.504501Z","shell.execute_reply.started":"2024-12-11T17:34:56.479395Z","shell.execute_reply":"2024-12-11T17:34:56.503270Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"                 author   fk_score  average_sentence_length\n0                 Aesop  68.432096                 8.176658\n1       Agatha_Christie  50.552960                 6.591788\n2  Ahmet_Hamdi_Tanpinar  33.215016                 8.483373","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>author</th>\n      <th>fk_score</th>\n      <th>average_sentence_length</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Aesop</td>\n      <td>68.432096</td>\n      <td>8.176658</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Agatha_Christie</td>\n      <td>50.552960</td>\n      <td>6.591788</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Ahmet_Hamdi_Tanpinar</td>\n      <td>33.215016</td>\n      <td>8.483373</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"# Предсказание автора по тексту\ndef predict_author(text, cleaned_text, author_profiles):    \n    fk_score, average_sentence_length = analyze_text(text, cleaned_text)\n\n    authors = author_profiles['author']\n    scores = dict.fromkeys(authors, 0)\n    \n    for author in authors:\n        author_fk, author_sentence_length = author_profiles.set_index('author').loc[author]['fk_score'],\\\n                                            author_profiles.set_index('author').loc[author]['average_sentence_length']\n\n        score = 0\n        # Сравниваем длинну предложений\n        if abs(average_sentence_length - author_sentence_length) < 1:\n            score += 1\n\n        # Сравниваем сложность текста\n        if abs(fk_score - author_fk) < 10:\n            score += 1\n            \n        scores[author] = score\n    \n    predicted_author = max(scores, key=scores.get)\n    \n    return predicted_author","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T17:34:56.506049Z","iopub.execute_input":"2024-12-11T17:34:56.506445Z","iopub.status.idle":"2024-12-11T17:34:56.519212Z","shell.execute_reply.started":"2024-12-11T17:34:56.506395Z","shell.execute_reply":"2024-12-11T17:34:56.517920Z"}},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":"Попробуем сделать предсказание на тренировочных данных.","metadata":{}},{"cell_type":"code","source":"y_pred = X_test.apply(lambda row: predict_author(row['text'], row['text_cleaned'], author_profiles), axis=1)\n\n# Расчитываем метрики\nrule_based_metrics = metrics(y_pred, y_test)\nrule_based_metrics","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T17:34:56.520491Z","iopub.execute_input":"2024-12-11T17:34:56.521077Z","iopub.status.idle":"2024-12-11T17:35:35.507452Z","shell.execute_reply.started":"2024-12-11T17:34:56.521012Z","shell.execute_reply":"2024-12-11T17:35:35.506069Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"              Metric     Score\n0           Accuracy  0.058824\n1  Precision (Macro)  0.032308\n2  Precision (Micro)  0.058824\n3     Recall (Macro)  0.046154\n4     Recall (Micro)  0.058824\n5   F1 Score (Macro)  0.033566\n6   F1 Score (Micro)  0.058824\n7            ROC AUC       NaN","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Metric</th>\n      <th>Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Accuracy</td>\n      <td>0.058824</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Precision (Macro)</td>\n      <td>0.032308</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Precision (Micro)</td>\n      <td>0.058824</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Recall (Macro)</td>\n      <td>0.046154</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Recall (Micro)</td>\n      <td>0.058824</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>F1 Score (Macro)</td>\n      <td>0.033566</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>F1 Score (Micro)</td>\n      <td>0.058824</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>ROC AUC</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":24},{"cell_type":"markdown","source":"Метрики низкие. Возможно, стоит добавить больше правил или пересмотреть текущие.","metadata":{}},{"cell_type":"markdown","source":"## Статистические подходы","metadata":{}},{"cell_type":"markdown","source":"Теперь нужно попробоват использовать ML и статистические методы. \n\n- BoW / TF-IDF + LogReg / SVM (классификация на основе ключевых слов)\n- N-grams + Naive Bayes (классификация с учетом последовательности слов)","metadata":{}},{"cell_type":"markdown","source":"### BoW + LogReg ","metadata":{}},{"cell_type":"code","source":"text_feature = 'text_cleaned_lemmatization'\nnum_features = ['fk_score', 'lexical_diversity', 'average_sentence_length', 'sentence_count', 'average_word_length', 'syllable_count']\n\npreprocessor = ColumnTransformer(\n    transformers = [('text', CountVectorizer(), text_feature),\n                    ('num', StandardScaler(), num_features)],\n    remainder='drop'\n)\n\n# Создание Pipeline\nlog_reg = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('model', LogisticRegression(random_state=RANDOM_STATE))\n])\n\n# Определим параметры\nlog_reg_params =[\n    {'preprocessor__text__max_df': np.arange(0.7, 1, 0.1),\n     'preprocessor__text__min_df': np.arange(0.1, 0.4, 0.1),  \n     'preprocessor__text__max_features': [1500, 3500, 5000, 8000, 10000, 20000, 50000],\n     'model__C': [0.01, 0.1, 1, 5, 10, 30, 50, 150]}\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T17:35:35.509134Z","iopub.execute_input":"2024-12-11T17:35:35.509502Z","iopub.status.idle":"2024-12-11T17:35:35.518175Z","shell.execute_reply.started":"2024-12-11T17:35:35.509464Z","shell.execute_reply":"2024-12-11T17:35:35.516849Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"rand_search = RandomizedSearchCV(log_reg, log_reg_params, n_iter=10, scoring='accuracy', cv=3, verbose=3, random_state=RANDOM_STATE)\nrand_search.fit(X_train, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T17:35:35.519952Z","iopub.execute_input":"2024-12-11T17:35:35.520428Z","iopub.status.idle":"2024-12-11T17:51:34.483660Z","shell.execute_reply.started":"2024-12-11T17:35:35.520391Z","shell.execute_reply":"2024-12-11T17:51:34.482318Z"}},"outputs":[{"name":"stdout","text":"Fitting 3 folds for each of 10 candidates, totalling 30 fits\n[CV 1/3] END model__C=30, preprocessor__text__max_df=0.9999999999999999, preprocessor__text__max_features=1500, preprocessor__text__min_df=0.2;, score=0.587 total time=  24.7s\n[CV 2/3] END model__C=30, preprocessor__text__max_df=0.9999999999999999, preprocessor__text__max_features=1500, preprocessor__text__min_df=0.2;, score=0.653 total time=  23.0s\n[CV 3/3] END model__C=30, preprocessor__text__max_df=0.9999999999999999, preprocessor__text__max_features=1500, preprocessor__text__min_df=0.2;, score=0.587 total time=  25.2s\n[CV 1/3] END model__C=30, preprocessor__text__max_df=0.7, preprocessor__text__max_features=1500, preprocessor__text__min_df=0.30000000000000004;, score=0.463 total time=  22.3s\n[CV 2/3] END model__C=30, preprocessor__text__max_df=0.7, preprocessor__text__max_features=1500, preprocessor__text__min_df=0.30000000000000004;, score=0.603 total time=  23.2s\n[CV 3/3] END model__C=30, preprocessor__text__max_df=0.7, preprocessor__text__max_features=1500, preprocessor__text__min_df=0.30000000000000004;, score=0.479 total time=  23.1s\n[CV 1/3] END model__C=1, preprocessor__text__max_df=0.7999999999999999, preprocessor__text__max_features=5000, preprocessor__text__min_df=0.2;, score=0.562 total time=  32.9s\n[CV 2/3] END model__C=1, preprocessor__text__max_df=0.7999999999999999, preprocessor__text__max_features=5000, preprocessor__text__min_df=0.2;, score=0.579 total time=  33.3s\n[CV 3/3] END model__C=1, preprocessor__text__max_df=0.7999999999999999, preprocessor__text__max_features=5000, preprocessor__text__min_df=0.2;, score=0.570 total time=  31.8s\n[CV 1/3] END model__C=0.01, preprocessor__text__max_df=0.8999999999999999, preprocessor__text__max_features=8000, preprocessor__text__min_df=0.2;, score=0.628 total time=  36.6s\n[CV 2/3] END model__C=0.01, preprocessor__text__max_df=0.8999999999999999, preprocessor__text__max_features=8000, preprocessor__text__min_df=0.2;, score=0.628 total time=  39.8s\n[CV 3/3] END model__C=0.01, preprocessor__text__max_df=0.8999999999999999, preprocessor__text__max_features=8000, preprocessor__text__min_df=0.2;, score=0.388 total time=  37.4s\n[CV 1/3] END model__C=10, preprocessor__text__max_df=0.7, preprocessor__text__max_features=50000, preprocessor__text__min_df=0.2;, score=0.529 total time=  34.8s\n[CV 2/3] END model__C=10, preprocessor__text__max_df=0.7, preprocessor__text__max_features=50000, preprocessor__text__min_df=0.2;, score=0.554 total time=  41.4s\n[CV 3/3] END model__C=10, preprocessor__text__max_df=0.7, preprocessor__text__max_features=50000, preprocessor__text__min_df=0.2;, score=0.537 total time=  37.6s\n[CV 1/3] END model__C=150, preprocessor__text__max_df=0.7, preprocessor__text__max_features=5000, preprocessor__text__min_df=0.30000000000000004;, score=0.521 total time=  29.4s\n[CV 2/3] END model__C=150, preprocessor__text__max_df=0.7, preprocessor__text__max_features=5000, preprocessor__text__min_df=0.30000000000000004;, score=0.620 total time=  36.0s\n[CV 3/3] END model__C=150, preprocessor__text__max_df=0.7, preprocessor__text__max_features=5000, preprocessor__text__min_df=0.30000000000000004;, score=0.529 total time=  31.5s\n[CV 1/3] END model__C=5, preprocessor__text__max_df=0.7, preprocessor__text__max_features=1500, preprocessor__text__min_df=0.30000000000000004;, score=0.471 total time=  24.2s\n[CV 2/3] END model__C=5, preprocessor__text__max_df=0.7, preprocessor__text__max_features=1500, preprocessor__text__min_df=0.30000000000000004;, score=0.595 total time=  23.5s\n[CV 3/3] END model__C=5, preprocessor__text__max_df=0.7, preprocessor__text__max_features=1500, preprocessor__text__min_df=0.30000000000000004;, score=0.496 total time=  22.1s\n[CV 1/3] END model__C=50, preprocessor__text__max_df=0.9999999999999999, preprocessor__text__max_features=8000, preprocessor__text__min_df=0.4;, score=0.653 total time=  30.3s\n[CV 2/3] END model__C=50, preprocessor__text__max_df=0.9999999999999999, preprocessor__text__max_features=8000, preprocessor__text__min_df=0.4;, score=0.678 total time=  33.3s\n[CV 3/3] END model__C=50, preprocessor__text__max_df=0.9999999999999999, preprocessor__text__max_features=8000, preprocessor__text__min_df=0.4;, score=0.645 total time=  35.7s\n[CV 1/3] END model__C=0.1, preprocessor__text__max_df=0.7, preprocessor__text__max_features=1500, preprocessor__text__min_df=0.30000000000000004;, score=0.455 total time=  22.6s\n[CV 2/3] END model__C=0.1, preprocessor__text__max_df=0.7, preprocessor__text__max_features=1500, preprocessor__text__min_df=0.30000000000000004;, score=0.562 total time=  21.4s\n[CV 3/3] END model__C=0.1, preprocessor__text__max_df=0.7, preprocessor__text__max_features=1500, preprocessor__text__min_df=0.30000000000000004;, score=0.512 total time=  21.9s\n[CV 1/3] END model__C=0.1, preprocessor__text__max_df=0.7999999999999999, preprocessor__text__max_features=50000, preprocessor__text__min_df=0.2;, score=0.562 total time=  35.9s\n[CV 2/3] END model__C=0.1, preprocessor__text__max_df=0.7999999999999999, preprocessor__text__max_features=50000, preprocessor__text__min_df=0.2;, score=0.579 total time=  41.1s\n[CV 3/3] END model__C=0.1, preprocessor__text__max_df=0.7999999999999999, preprocessor__text__max_features=50000, preprocessor__text__min_df=0.2;, score=0.570 total time=  38.6s\n","output_type":"stream"},{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"RandomizedSearchCV(cv=3,\n                   estimator=Pipeline(steps=[('preprocessor',\n                                              ColumnTransformer(transformers=[('text',\n                                                                               CountVectorizer(),\n                                                                               'text_cleaned_lemmatization'),\n                                                                              ('num',\n                                                                               StandardScaler(),\n                                                                               ['fk_score',\n                                                                                'lexical_diversity',\n                                                                                'average_sentence_length',\n                                                                                'sentence_count',\n                                                                                'average_word_length',\n                                                                                'syllable_count'])])),\n                                             ('model',\n                                              LogisticRegression(random_state=17))]),\n                   param_distributions=[{'model__C': [0.01, 0.1, 1, 5, 10, 30,\n                                                      50, 150],\n                                         'preprocessor__text__max_df': array([0.7, 0.8, 0.9, 1. ]),\n                                         'preprocessor__text__max_features': [1500,\n                                                                              3500,\n                                                                              5000,\n                                                                              8000,\n                                                                              10000,\n                                                                              20000,\n                                                                              50000],\n                                         'preprocessor__text__min_df': array([0.1, 0.2, 0.3, 0.4])}],\n                   random_state=17, scoring='accuracy', verbose=3)","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3,\n                   estimator=Pipeline(steps=[(&#x27;preprocessor&#x27;,\n                                              ColumnTransformer(transformers=[(&#x27;text&#x27;,\n                                                                               CountVectorizer(),\n                                                                               &#x27;text_cleaned_lemmatization&#x27;),\n                                                                              (&#x27;num&#x27;,\n                                                                               StandardScaler(),\n                                                                               [&#x27;fk_score&#x27;,\n                                                                                &#x27;lexical_diversity&#x27;,\n                                                                                &#x27;average_sentence_length&#x27;,\n                                                                                &#x27;sentence_count&#x27;,\n                                                                                &#x27;average_word_length&#x27;,\n                                                                                &#x27;syllable_count&#x27;])])),\n                                             (&#x27;model&#x27;,\n                                              LogisticRegression(random_state=17))]),\n                   param_distributions=[{&#x27;model__C&#x27;: [0.01, 0.1, 1, 5, 10, 30,\n                                                      50, 150],\n                                         &#x27;preprocessor__text__max_df&#x27;: array([0.7, 0.8, 0.9, 1. ]),\n                                         &#x27;preprocessor__text__max_features&#x27;: [1500,\n                                                                              3500,\n                                                                              5000,\n                                                                              8000,\n                                                                              10000,\n                                                                              20000,\n                                                                              50000],\n                                         &#x27;preprocessor__text__min_df&#x27;: array([0.1, 0.2, 0.3, 0.4])}],\n                   random_state=17, scoring=&#x27;accuracy&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3,\n                   estimator=Pipeline(steps=[(&#x27;preprocessor&#x27;,\n                                              ColumnTransformer(transformers=[(&#x27;text&#x27;,\n                                                                               CountVectorizer(),\n                                                                               &#x27;text_cleaned_lemmatization&#x27;),\n                                                                              (&#x27;num&#x27;,\n                                                                               StandardScaler(),\n                                                                               [&#x27;fk_score&#x27;,\n                                                                                &#x27;lexical_diversity&#x27;,\n                                                                                &#x27;average_sentence_length&#x27;,\n                                                                                &#x27;sentence_count&#x27;,\n                                                                                &#x27;average_word_length&#x27;,\n                                                                                &#x27;syllable_count&#x27;])])),\n                                             (&#x27;model&#x27;,\n                                              LogisticRegression(random_state=17))]),\n                   param_distributions=[{&#x27;model__C&#x27;: [0.01, 0.1, 1, 5, 10, 30,\n                                                      50, 150],\n                                         &#x27;preprocessor__text__max_df&#x27;: array([0.7, 0.8, 0.9, 1. ]),\n                                         &#x27;preprocessor__text__max_features&#x27;: [1500,\n                                                                              3500,\n                                                                              5000,\n                                                                              8000,\n                                                                              10000,\n                                                                              20000,\n                                                                              50000],\n                                         &#x27;preprocessor__text__min_df&#x27;: array([0.1, 0.2, 0.3, 0.4])}],\n                   random_state=17, scoring=&#x27;accuracy&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n                 ColumnTransformer(transformers=[(&#x27;text&#x27;, CountVectorizer(),\n                                                  &#x27;text_cleaned_lemmatization&#x27;),\n                                                 (&#x27;num&#x27;, StandardScaler(),\n                                                  [&#x27;fk_score&#x27;,\n                                                   &#x27;lexical_diversity&#x27;,\n                                                   &#x27;average_sentence_length&#x27;,\n                                                   &#x27;sentence_count&#x27;,\n                                                   &#x27;average_word_length&#x27;,\n                                                   &#x27;syllable_count&#x27;])])),\n                (&#x27;model&#x27;, LogisticRegression(random_state=17))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;text&#x27;, CountVectorizer(),\n                                 &#x27;text_cleaned_lemmatization&#x27;),\n                                (&#x27;num&#x27;, StandardScaler(),\n                                 [&#x27;fk_score&#x27;, &#x27;lexical_diversity&#x27;,\n                                  &#x27;average_sentence_length&#x27;, &#x27;sentence_count&#x27;,\n                                  &#x27;average_word_length&#x27;, &#x27;syllable_count&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">text</label><div class=\"sk-toggleable__content\"><pre>text_cleaned_lemmatization</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[&#x27;fk_score&#x27;, &#x27;lexical_diversity&#x27;, &#x27;average_sentence_length&#x27;, &#x27;sentence_count&#x27;, &#x27;average_word_length&#x27;, &#x27;syllable_count&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=17)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"cv_result_cols = ['param_preprocessor__text__min_df', 'param_preprocessor__text__max_features','param_preprocessor__text__max_df', \n                  'param_model__C', 'mean_test_score', 'std_test_score', 'rank_test_score']\n\nprint(f'Лучшее значение метрики: {rand_search.best_score_}')\n\n\ncv_results = pd.DataFrame(rand_search.cv_results_)[cv_result_cols].sort_values(by=['rank_test_score'])\ncv_results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T17:51:34.485212Z","iopub.execute_input":"2024-12-11T17:51:34.485565Z","iopub.status.idle":"2024-12-11T17:51:34.505129Z","shell.execute_reply.started":"2024-12-11T17:51:34.485530Z","shell.execute_reply":"2024-12-11T17:51:34.503903Z"}},"outputs":[{"name":"stdout","text":"Лучшее значение метрики: 0.6584022038567493\n","output_type":"stream"},{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"  param_preprocessor__text__min_df param_preprocessor__text__max_features  \\\n7                              0.4                                   8000   \n0                              0.2                                   1500   \n2                              0.2                                   5000   \n9                              0.2                                  50000   \n5                              0.3                                   5000   \n3                              0.2                                   8000   \n4                              0.2                                  50000   \n6                              0.3                                   1500   \n1                              0.3                                   1500   \n8                              0.3                                   1500   \n\n  param_preprocessor__text__max_df param_model__C  mean_test_score  \\\n7                              1.0             50         0.658402   \n0                              1.0             30         0.608815   \n2                              0.8              1         0.570248   \n9                              0.8            0.1         0.570248   \n5                              0.7            150         0.556474   \n3                              0.9           0.01         0.548209   \n4                              0.7             10         0.539945   \n6                              0.7              5         0.520661   \n1                              0.7             30         0.515152   \n8                              0.7            0.1         0.509642   \n\n   std_test_score  rank_test_score  \n7        0.014047                1  \n0        0.031167                2  \n2        0.006748                3  \n9        0.006748                3  \n5        0.044930                5  \n3        0.112981                6  \n4        0.010308                7  \n6        0.053560                8  \n1        0.062699                9  \n8        0.043905               10  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>param_preprocessor__text__min_df</th>\n      <th>param_preprocessor__text__max_features</th>\n      <th>param_preprocessor__text__max_df</th>\n      <th>param_model__C</th>\n      <th>mean_test_score</th>\n      <th>std_test_score</th>\n      <th>rank_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7</th>\n      <td>0.4</td>\n      <td>8000</td>\n      <td>1.0</td>\n      <td>50</td>\n      <td>0.658402</td>\n      <td>0.014047</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.2</td>\n      <td>1500</td>\n      <td>1.0</td>\n      <td>30</td>\n      <td>0.608815</td>\n      <td>0.031167</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.2</td>\n      <td>5000</td>\n      <td>0.8</td>\n      <td>1</td>\n      <td>0.570248</td>\n      <td>0.006748</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.2</td>\n      <td>50000</td>\n      <td>0.8</td>\n      <td>0.1</td>\n      <td>0.570248</td>\n      <td>0.006748</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.3</td>\n      <td>5000</td>\n      <td>0.7</td>\n      <td>150</td>\n      <td>0.556474</td>\n      <td>0.044930</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.2</td>\n      <td>8000</td>\n      <td>0.9</td>\n      <td>0.01</td>\n      <td>0.548209</td>\n      <td>0.112981</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.2</td>\n      <td>50000</td>\n      <td>0.7</td>\n      <td>10</td>\n      <td>0.539945</td>\n      <td>0.010308</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.3</td>\n      <td>1500</td>\n      <td>0.7</td>\n      <td>5</td>\n      <td>0.520661</td>\n      <td>0.053560</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.3</td>\n      <td>1500</td>\n      <td>0.7</td>\n      <td>30</td>\n      <td>0.515152</td>\n      <td>0.062699</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.3</td>\n      <td>1500</td>\n      <td>0.7</td>\n      <td>0.1</td>\n      <td>0.509642</td>\n      <td>0.043905</td>\n      <td>10</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"log_reg_BoW = rand_search.best_estimator_\n\ny_pred = log_reg_BoW.predict(X_test)\nlog_reg_bow_metrics = metrics(y_pred, y_test)\nlog_reg_bow_metrics ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T17:51:34.511092Z","iopub.execute_input":"2024-12-11T17:51:34.511445Z","iopub.status.idle":"2024-12-11T17:51:37.464906Z","shell.execute_reply.started":"2024-12-11T17:51:34.511413Z","shell.execute_reply":"2024-12-11T17:51:37.462594Z"}},"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"              Metric     Score\n0           Accuracy  0.549020\n1  Precision (Macro)  0.399691\n2  Precision (Micro)  0.549020\n3     Recall (Macro)  0.518519\n4     Recall (Micro)  0.549020\n5   F1 Score (Macro)  0.432451\n6   F1 Score (Micro)  0.549020\n7            ROC AUC       NaN","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Metric</th>\n      <th>Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Accuracy</td>\n      <td>0.549020</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Precision (Macro)</td>\n      <td>0.399691</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Precision (Micro)</td>\n      <td>0.549020</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Recall (Macro)</td>\n      <td>0.518519</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Recall (Micro)</td>\n      <td>0.549020</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>F1 Score (Macro)</td>\n      <td>0.432451</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>F1 Score (Micro)</td>\n      <td>0.549020</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>ROC AUC</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":28},{"cell_type":"markdown","source":"### IF-IDF + LogReg ","metadata":{}},{"cell_type":"code","source":"text_feature = 'text_cleaned_lemmatization'\nnum_features = ['fk_score', 'lexical_diversity', 'average_sentence_length', 'sentence_count', 'average_word_length', 'syllable_count']\n\npreprocessor = ColumnTransformer(\n    transformers = [('text', TfidfVectorizer(), text_feature),\n                    ('num', StandardScaler(), num_features)],\n    remainder='drop'\n)\n\n# Создание Pipeline\nlog_reg = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('model', LogisticRegression(random_state=RANDOM_STATE))\n])\n\n# Определим параметры\nlog_reg_params =[\n    {'preprocessor__text__max_df': np.arange(0.7, 1, 0.1),\n     'preprocessor__text__min_df': np.arange(0.1, 0.4, 0.1),  \n     'preprocessor__text__max_features': [1500, 3500, 5000, 8000, 10000, 20000, 35000],\n     'model__C': [0.01, 0.1, 1, 5, 10, 30, 50, 150]}\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T17:51:37.466379Z","iopub.execute_input":"2024-12-11T17:51:37.466854Z","iopub.status.idle":"2024-12-11T17:51:37.483022Z","shell.execute_reply.started":"2024-12-11T17:51:37.466803Z","shell.execute_reply":"2024-12-11T17:51:37.480853Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"rand_search = RandomizedSearchCV(log_reg, log_reg_params, n_iter=10, scoring='accuracy', cv=3, verbose=3, random_state=RANDOM_STATE)\nrand_search.fit(X_train, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T17:51:37.484307Z","iopub.execute_input":"2024-12-11T17:51:37.484744Z","iopub.status.idle":"2024-12-11T18:04:10.927047Z","shell.execute_reply.started":"2024-12-11T17:51:37.484699Z","shell.execute_reply":"2024-12-11T18:04:10.926012Z"}},"outputs":[{"name":"stdout","text":"Fitting 3 folds for each of 10 candidates, totalling 30 fits\n[CV 1/3] END model__C=30, preprocessor__text__max_df=0.9999999999999999, preprocessor__text__max_features=1500, preprocessor__text__min_df=0.2;, score=0.397 total time=  22.6s\n[CV 2/3] END model__C=30, preprocessor__text__max_df=0.9999999999999999, preprocessor__text__max_features=1500, preprocessor__text__min_df=0.2;, score=0.678 total time=  20.3s\n[CV 3/3] END model__C=30, preprocessor__text__max_df=0.9999999999999999, preprocessor__text__max_features=1500, preprocessor__text__min_df=0.2;, score=0.521 total time=  20.6s\n[CV 1/3] END model__C=30, preprocessor__text__max_df=0.7, preprocessor__text__max_features=1500, preprocessor__text__min_df=0.30000000000000004;, score=0.397 total time=  21.6s\n[CV 2/3] END model__C=30, preprocessor__text__max_df=0.7, preprocessor__text__max_features=1500, preprocessor__text__min_df=0.30000000000000004;, score=0.628 total time=  20.1s\n[CV 3/3] END model__C=30, preprocessor__text__max_df=0.7, preprocessor__text__max_features=1500, preprocessor__text__min_df=0.30000000000000004;, score=0.430 total time=  20.8s\n[CV 1/3] END model__C=1, preprocessor__text__max_df=0.7999999999999999, preprocessor__text__max_features=5000, preprocessor__text__min_df=0.2;, score=0.273 total time=  28.6s\n[CV 2/3] END model__C=1, preprocessor__text__max_df=0.7999999999999999, preprocessor__text__max_features=5000, preprocessor__text__min_df=0.2;, score=0.570 total time=  24.4s\n[CV 3/3] END model__C=1, preprocessor__text__max_df=0.7999999999999999, preprocessor__text__max_features=5000, preprocessor__text__min_df=0.2;, score=0.273 total time=  25.3s\n[CV 1/3] END model__C=0.01, preprocessor__text__max_df=0.8999999999999999, preprocessor__text__max_features=8000, preprocessor__text__min_df=0.2;, score=0.165 total time=  20.9s\n[CV 2/3] END model__C=0.01, preprocessor__text__max_df=0.8999999999999999, preprocessor__text__max_features=8000, preprocessor__text__min_df=0.2;, score=0.182 total time=  24.2s\n[CV 3/3] END model__C=0.01, preprocessor__text__max_df=0.8999999999999999, preprocessor__text__max_features=8000, preprocessor__text__min_df=0.2;, score=0.157 total time=  22.3s\n[CV 1/3] END model__C=10, preprocessor__text__max_df=0.7, preprocessor__text__max_features=35000, preprocessor__text__min_df=0.2;, score=0.388 total time=  31.7s\n[CV 2/3] END model__C=10, preprocessor__text__max_df=0.7, preprocessor__text__max_features=35000, preprocessor__text__min_df=0.2;, score=0.620 total time=  34.6s\n[CV 3/3] END model__C=10, preprocessor__text__max_df=0.7, preprocessor__text__max_features=35000, preprocessor__text__min_df=0.2;, score=0.372 total time=  36.8s\n[CV 1/3] END model__C=150, preprocessor__text__max_df=0.7, preprocessor__text__max_features=5000, preprocessor__text__min_df=0.30000000000000004;, score=0.430 total time=  26.5s\n[CV 2/3] END model__C=150, preprocessor__text__max_df=0.7, preprocessor__text__max_features=5000, preprocessor__text__min_df=0.30000000000000004;, score=0.653 total time=  29.5s\n[CV 3/3] END model__C=150, preprocessor__text__max_df=0.7, preprocessor__text__max_features=5000, preprocessor__text__min_df=0.30000000000000004;, score=0.455 total time=  30.3s\n[CV 1/3] END model__C=5, preprocessor__text__max_df=0.7, preprocessor__text__max_features=1500, preprocessor__text__min_df=0.30000000000000004;, score=0.364 total time=  19.6s\n[CV 2/3] END model__C=5, preprocessor__text__max_df=0.7, preprocessor__text__max_features=1500, preprocessor__text__min_df=0.30000000000000004;, score=0.628 total time=  21.9s\n[CV 3/3] END model__C=5, preprocessor__text__max_df=0.7, preprocessor__text__max_features=1500, preprocessor__text__min_df=0.30000000000000004;, score=0.405 total time=  20.7s\n[CV 1/3] END model__C=50, preprocessor__text__max_df=0.9999999999999999, preprocessor__text__max_features=8000, preprocessor__text__min_df=0.4;, score=0.413 total time=  25.5s\n[CV 2/3] END model__C=50, preprocessor__text__max_df=0.9999999999999999, preprocessor__text__max_features=8000, preprocessor__text__min_df=0.4;, score=0.686 total time=  28.6s\n[CV 3/3] END model__C=50, preprocessor__text__max_df=0.9999999999999999, preprocessor__text__max_features=8000, preprocessor__text__min_df=0.4;, score=0.529 total time=  30.6s\n[CV 1/3] END model__C=0.1, preprocessor__text__max_df=0.7, preprocessor__text__max_features=1500, preprocessor__text__min_df=0.30000000000000004;, score=0.174 total time=  15.1s\n[CV 2/3] END model__C=0.1, preprocessor__text__max_df=0.7, preprocessor__text__max_features=1500, preprocessor__text__min_df=0.30000000000000004;, score=0.298 total time=  16.0s\n[CV 3/3] END model__C=0.1, preprocessor__text__max_df=0.7, preprocessor__text__max_features=1500, preprocessor__text__min_df=0.30000000000000004;, score=0.190 total time=  15.9s\n[CV 1/3] END model__C=0.1, preprocessor__text__max_df=0.7999999999999999, preprocessor__text__max_features=35000, preprocessor__text__min_df=0.2;, score=0.174 total time=  21.2s\n[CV 2/3] END model__C=0.1, preprocessor__text__max_df=0.7999999999999999, preprocessor__text__max_features=35000, preprocessor__text__min_df=0.2;, score=0.289 total time=  22.9s\n[CV 3/3] END model__C=0.1, preprocessor__text__max_df=0.7999999999999999, preprocessor__text__max_features=35000, preprocessor__text__min_df=0.2;, score=0.190 total time=  22.9s\n","output_type":"stream"},{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"RandomizedSearchCV(cv=3,\n                   estimator=Pipeline(steps=[('preprocessor',\n                                              ColumnTransformer(transformers=[('text',\n                                                                               TfidfVectorizer(),\n                                                                               'text_cleaned_lemmatization'),\n                                                                              ('num',\n                                                                               StandardScaler(),\n                                                                               ['fk_score',\n                                                                                'lexical_diversity',\n                                                                                'average_sentence_length',\n                                                                                'sentence_count',\n                                                                                'average_word_length',\n                                                                                'syllable_count'])])),\n                                             ('model',\n                                              LogisticRegression(random_state=17))]),\n                   param_distributions=[{'model__C': [0.01, 0.1, 1, 5, 10, 30,\n                                                      50, 150],\n                                         'preprocessor__text__max_df': array([0.7, 0.8, 0.9, 1. ]),\n                                         'preprocessor__text__max_features': [1500,\n                                                                              3500,\n                                                                              5000,\n                                                                              8000,\n                                                                              10000,\n                                                                              20000,\n                                                                              35000],\n                                         'preprocessor__text__min_df': array([0.1, 0.2, 0.3, 0.4])}],\n                   random_state=17, scoring='accuracy', verbose=3)","text/html":"<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3,\n                   estimator=Pipeline(steps=[(&#x27;preprocessor&#x27;,\n                                              ColumnTransformer(transformers=[(&#x27;text&#x27;,\n                                                                               TfidfVectorizer(),\n                                                                               &#x27;text_cleaned_lemmatization&#x27;),\n                                                                              (&#x27;num&#x27;,\n                                                                               StandardScaler(),\n                                                                               [&#x27;fk_score&#x27;,\n                                                                                &#x27;lexical_diversity&#x27;,\n                                                                                &#x27;average_sentence_length&#x27;,\n                                                                                &#x27;sentence_count&#x27;,\n                                                                                &#x27;average_word_length&#x27;,\n                                                                                &#x27;syllable_count&#x27;])])),\n                                             (&#x27;model&#x27;,\n                                              LogisticRegression(random_state=17))]),\n                   param_distributions=[{&#x27;model__C&#x27;: [0.01, 0.1, 1, 5, 10, 30,\n                                                      50, 150],\n                                         &#x27;preprocessor__text__max_df&#x27;: array([0.7, 0.8, 0.9, 1. ]),\n                                         &#x27;preprocessor__text__max_features&#x27;: [1500,\n                                                                              3500,\n                                                                              5000,\n                                                                              8000,\n                                                                              10000,\n                                                                              20000,\n                                                                              35000],\n                                         &#x27;preprocessor__text__min_df&#x27;: array([0.1, 0.2, 0.3, 0.4])}],\n                   random_state=17, scoring=&#x27;accuracy&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3,\n                   estimator=Pipeline(steps=[(&#x27;preprocessor&#x27;,\n                                              ColumnTransformer(transformers=[(&#x27;text&#x27;,\n                                                                               TfidfVectorizer(),\n                                                                               &#x27;text_cleaned_lemmatization&#x27;),\n                                                                              (&#x27;num&#x27;,\n                                                                               StandardScaler(),\n                                                                               [&#x27;fk_score&#x27;,\n                                                                                &#x27;lexical_diversity&#x27;,\n                                                                                &#x27;average_sentence_length&#x27;,\n                                                                                &#x27;sentence_count&#x27;,\n                                                                                &#x27;average_word_length&#x27;,\n                                                                                &#x27;syllable_count&#x27;])])),\n                                             (&#x27;model&#x27;,\n                                              LogisticRegression(random_state=17))]),\n                   param_distributions=[{&#x27;model__C&#x27;: [0.01, 0.1, 1, 5, 10, 30,\n                                                      50, 150],\n                                         &#x27;preprocessor__text__max_df&#x27;: array([0.7, 0.8, 0.9, 1. ]),\n                                         &#x27;preprocessor__text__max_features&#x27;: [1500,\n                                                                              3500,\n                                                                              5000,\n                                                                              8000,\n                                                                              10000,\n                                                                              20000,\n                                                                              35000],\n                                         &#x27;preprocessor__text__min_df&#x27;: array([0.1, 0.2, 0.3, 0.4])}],\n                   random_state=17, scoring=&#x27;accuracy&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n                 ColumnTransformer(transformers=[(&#x27;text&#x27;, TfidfVectorizer(),\n                                                  &#x27;text_cleaned_lemmatization&#x27;),\n                                                 (&#x27;num&#x27;, StandardScaler(),\n                                                  [&#x27;fk_score&#x27;,\n                                                   &#x27;lexical_diversity&#x27;,\n                                                   &#x27;average_sentence_length&#x27;,\n                                                   &#x27;sentence_count&#x27;,\n                                                   &#x27;average_word_length&#x27;,\n                                                   &#x27;syllable_count&#x27;])])),\n                (&#x27;model&#x27;, LogisticRegression(random_state=17))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;text&#x27;, TfidfVectorizer(),\n                                 &#x27;text_cleaned_lemmatization&#x27;),\n                                (&#x27;num&#x27;, StandardScaler(),\n                                 [&#x27;fk_score&#x27;, &#x27;lexical_diversity&#x27;,\n                                  &#x27;average_sentence_length&#x27;, &#x27;sentence_count&#x27;,\n                                  &#x27;average_word_length&#x27;, &#x27;syllable_count&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">text</label><div class=\"sk-toggleable__content\"><pre>text_cleaned_lemmatization</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[&#x27;fk_score&#x27;, &#x27;lexical_diversity&#x27;, &#x27;average_sentence_length&#x27;, &#x27;sentence_count&#x27;, &#x27;average_word_length&#x27;, &#x27;syllable_count&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=17)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"cv_result_cols = ['param_preprocessor__text__min_df', 'param_preprocessor__text__max_features','param_preprocessor__text__max_df', \n                  'param_model__C', 'mean_test_score', 'std_test_score', 'rank_test_score']\n\nprint(f'Лучшее значение метрики: {rand_search.best_score_}')\n\n\n\ncv_results = pd.DataFrame(rand_search.cv_results_)[cv_result_cols].sort_values(by=['rank_test_score'])\ncv_results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T18:04:10.928327Z","iopub.execute_input":"2024-12-11T18:04:10.934165Z","iopub.status.idle":"2024-12-11T18:04:10.954359Z","shell.execute_reply.started":"2024-12-11T18:04:10.934096Z","shell.execute_reply":"2024-12-11T18:04:10.953208Z"}},"outputs":[{"name":"stdout","text":"Лучшее значение метрики: 0.5426997245179064\n","output_type":"stream"},{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"  param_preprocessor__text__min_df param_preprocessor__text__max_features  \\\n7                              0.4                                   8000   \n0                              0.2                                   1500   \n5                              0.3                                   5000   \n1                              0.3                                   1500   \n6                              0.3                                   1500   \n4                              0.2                                  35000   \n2                              0.2                                   5000   \n8                              0.3                                   1500   \n9                              0.2                                  35000   \n3                              0.2                                   8000   \n\n  param_preprocessor__text__max_df param_model__C  mean_test_score  \\\n7                              1.0             50         0.542700   \n0                              1.0             30         0.531680   \n5                              0.7            150         0.512397   \n1                              0.7             30         0.484848   \n6                              0.7              5         0.465565   \n4                              0.7             10         0.460055   \n2                              0.8              1         0.371901   \n8                              0.7            0.1         0.220386   \n9                              0.8            0.1         0.217631   \n3                              0.9           0.01         0.168044   \n\n   std_test_score  rank_test_score  \n7        0.111766                1  \n0        0.114979                2  \n5        0.099860                3  \n1        0.102189                4  \n6        0.116161                5  \n4        0.113183                6  \n2        0.140253                7  \n8        0.054959                8  \n9        0.051094                9  \n3        0.010308               10  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>param_preprocessor__text__min_df</th>\n      <th>param_preprocessor__text__max_features</th>\n      <th>param_preprocessor__text__max_df</th>\n      <th>param_model__C</th>\n      <th>mean_test_score</th>\n      <th>std_test_score</th>\n      <th>rank_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7</th>\n      <td>0.4</td>\n      <td>8000</td>\n      <td>1.0</td>\n      <td>50</td>\n      <td>0.542700</td>\n      <td>0.111766</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.2</td>\n      <td>1500</td>\n      <td>1.0</td>\n      <td>30</td>\n      <td>0.531680</td>\n      <td>0.114979</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.3</td>\n      <td>5000</td>\n      <td>0.7</td>\n      <td>150</td>\n      <td>0.512397</td>\n      <td>0.099860</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.3</td>\n      <td>1500</td>\n      <td>0.7</td>\n      <td>30</td>\n      <td>0.484848</td>\n      <td>0.102189</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.3</td>\n      <td>1500</td>\n      <td>0.7</td>\n      <td>5</td>\n      <td>0.465565</td>\n      <td>0.116161</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.2</td>\n      <td>35000</td>\n      <td>0.7</td>\n      <td>10</td>\n      <td>0.460055</td>\n      <td>0.113183</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.2</td>\n      <td>5000</td>\n      <td>0.8</td>\n      <td>1</td>\n      <td>0.371901</td>\n      <td>0.140253</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.3</td>\n      <td>1500</td>\n      <td>0.7</td>\n      <td>0.1</td>\n      <td>0.220386</td>\n      <td>0.054959</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.2</td>\n      <td>35000</td>\n      <td>0.8</td>\n      <td>0.1</td>\n      <td>0.217631</td>\n      <td>0.051094</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.2</td>\n      <td>8000</td>\n      <td>0.9</td>\n      <td>0.01</td>\n      <td>0.168044</td>\n      <td>0.010308</td>\n      <td>10</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"log_reg_tfidf = rand_search.best_estimator_\n\ny_pred = log_reg_tfidf.predict(X_test)\n#y_pred_proba = log_reg_tfidf.predict_proba(X_test)\nlog_reg_tfidf_metrics = metrics(y_pred, y_test)\nlog_reg_tfidf_metrics ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T18:04:10.956162Z","iopub.execute_input":"2024-12-11T18:04:10.956595Z","iopub.status.idle":"2024-12-11T18:04:13.904666Z","shell.execute_reply.started":"2024-12-11T18:04:10.956548Z","shell.execute_reply":"2024-12-11T18:04:13.902970Z"}},"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"              Metric     Score\n0           Accuracy  0.568627\n1  Precision (Macro)  0.442949\n2  Precision (Micro)  0.568627\n3     Recall (Macro)  0.557692\n4     Recall (Micro)  0.568627\n5   F1 Score (Macro)  0.474359\n6   F1 Score (Micro)  0.568627\n7            ROC AUC       NaN","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Metric</th>\n      <th>Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Accuracy</td>\n      <td>0.568627</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Precision (Macro)</td>\n      <td>0.442949</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Precision (Micro)</td>\n      <td>0.568627</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Recall (Macro)</td>\n      <td>0.557692</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Recall (Micro)</td>\n      <td>0.568627</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>F1 Score (Macro)</td>\n      <td>0.474359</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>F1 Score (Micro)</td>\n      <td>0.568627</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>ROC AUC</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":32},{"cell_type":"markdown","source":"### BoW + ngrams + Logistic Regression","metadata":{}},{"cell_type":"code","source":"text_feature = 'text_cleaned_lemmatization'\nnum_features = ['fk_score', 'lexical_diversity', 'average_sentence_length', 'sentence_count', 'average_word_length', 'syllable_count']\n\npreprocessor = ColumnTransformer(\n    transformers = [('text', CountVectorizer(ngram_range=(1, 2)), text_feature),\n                    ('num', StandardScaler(), num_features)],\n    remainder='drop'\n)\n\n# Создание Pipeline\nlog_reg = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('model', LogisticRegression(random_state=RANDOM_STATE))\n])\n\n# Определим параметры\nlog_reg_params =[\n    {'preprocessor__text__max_df': np.arange(0.7, 1, 0.1),\n     'preprocessor__text__min_df': np.arange(0.1, 0.4, 0.1),  \n     'preprocessor__text__max_features': [1500, 3500, 5000, 8000, 10000],\n     'model__C': [0.01, 0.1, 1, 5, 10, 30, 50, 150]}\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T18:04:13.906382Z","iopub.execute_input":"2024-12-11T18:04:13.906841Z","iopub.status.idle":"2024-12-11T18:04:13.929436Z","shell.execute_reply.started":"2024-12-11T18:04:13.906770Z","shell.execute_reply":"2024-12-11T18:04:13.928034Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"rand_search = RandomizedSearchCV(log_reg, log_reg_params, n_iter=5, scoring='accuracy', cv=3, verbose=3, random_state=RANDOM_STATE)\nrand_search.fit(X_train, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T18:04:13.931041Z","iopub.execute_input":"2024-12-11T18:04:13.931605Z","iopub.status.idle":"2024-12-11T18:25:12.554078Z","shell.execute_reply.started":"2024-12-11T18:04:13.931540Z","shell.execute_reply":"2024-12-11T18:25:12.552931Z"}},"outputs":[{"name":"stdout","text":"Fitting 3 folds for each of 5 candidates, totalling 15 fits\n[CV 1/3] END model__C=150, preprocessor__text__max_df=0.9999999999999999, preprocessor__text__max_features=1500, preprocessor__text__min_df=0.4;, score=0.686 total time= 1.1min\n[CV 2/3] END model__C=150, preprocessor__text__max_df=0.9999999999999999, preprocessor__text__max_features=1500, preprocessor__text__min_df=0.4;, score=0.661 total time= 1.3min\n[CV 3/3] END model__C=150, preprocessor__text__max_df=0.9999999999999999, preprocessor__text__max_features=1500, preprocessor__text__min_df=0.4;, score=0.587 total time= 1.4min\n[CV 1/3] END model__C=5, preprocessor__text__max_df=0.7, preprocessor__text__max_features=1500, preprocessor__text__min_df=0.2;, score=0.496 total time= 1.0min\n[CV 2/3] END model__C=5, preprocessor__text__max_df=0.7, preprocessor__text__max_features=1500, preprocessor__text__min_df=0.2;, score=0.595 total time= 1.3min\n[CV 3/3] END model__C=5, preprocessor__text__max_df=0.7, preprocessor__text__max_features=1500, preprocessor__text__min_df=0.2;, score=0.512 total time= 1.3min\n[CV 1/3] END model__C=0.1, preprocessor__text__max_df=0.9999999999999999, preprocessor__text__max_features=1500, preprocessor__text__min_df=0.4;, score=0.669 total time=  58.5s\n[CV 2/3] END model__C=0.1, preprocessor__text__max_df=0.9999999999999999, preprocessor__text__max_features=1500, preprocessor__text__min_df=0.4;, score=0.636 total time= 1.2min\n[CV 3/3] END model__C=0.1, preprocessor__text__max_df=0.9999999999999999, preprocessor__text__max_features=1500, preprocessor__text__min_df=0.4;, score=0.595 total time= 1.3min\n[CV 1/3] END model__C=10, preprocessor__text__max_df=0.9999999999999999, preprocessor__text__max_features=5000, preprocessor__text__min_df=0.30000000000000004;, score=0.678 total time= 1.2min\n[CV 2/3] END model__C=10, preprocessor__text__max_df=0.9999999999999999, preprocessor__text__max_features=5000, preprocessor__text__min_df=0.30000000000000004;, score=0.694 total time= 1.5min\n[CV 3/3] END model__C=10, preprocessor__text__max_df=0.9999999999999999, preprocessor__text__max_features=5000, preprocessor__text__min_df=0.30000000000000004;, score=0.587 total time= 1.6min\n[CV 1/3] END model__C=30, preprocessor__text__max_df=0.7, preprocessor__text__max_features=3500, preprocessor__text__min_df=0.30000000000000004;, score=0.496 total time= 1.1min\n[CV 2/3] END model__C=30, preprocessor__text__max_df=0.7, preprocessor__text__max_features=3500, preprocessor__text__min_df=0.30000000000000004;, score=0.612 total time= 1.3min\n[CV 3/3] END model__C=30, preprocessor__text__max_df=0.7, preprocessor__text__max_features=3500, preprocessor__text__min_df=0.30000000000000004;, score=0.570 total time= 1.4min\n","output_type":"stream"},{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"RandomizedSearchCV(cv=3,\n                   estimator=Pipeline(steps=[('preprocessor',\n                                              ColumnTransformer(transformers=[('text',\n                                                                               CountVectorizer(ngram_range=(1,\n                                                                                                            2)),\n                                                                               'text_cleaned_lemmatization'),\n                                                                              ('num',\n                                                                               StandardScaler(),\n                                                                               ['fk_score',\n                                                                                'lexical_diversity',\n                                                                                'average_sentence_length',\n                                                                                'sentence_count',\n                                                                                'average_word_length',\n                                                                                'syllable_count'])])),\n                                             ('model',\n                                              LogisticRegression(random_state=17))]),\n                   n_iter=5,\n                   param_distributions=[{'model__C': [0.01, 0.1, 1, 5, 10, 30,\n                                                      50, 150],\n                                         'preprocessor__text__max_df': array([0.7, 0.8, 0.9, 1. ]),\n                                         'preprocessor__text__max_features': [1500,\n                                                                              3500,\n                                                                              5000,\n                                                                              8000,\n                                                                              10000],\n                                         'preprocessor__text__min_df': array([0.1, 0.2, 0.3, 0.4])}],\n                   random_state=17, scoring='accuracy', verbose=3)","text/html":"<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3,\n                   estimator=Pipeline(steps=[(&#x27;preprocessor&#x27;,\n                                              ColumnTransformer(transformers=[(&#x27;text&#x27;,\n                                                                               CountVectorizer(ngram_range=(1,\n                                                                                                            2)),\n                                                                               &#x27;text_cleaned_lemmatization&#x27;),\n                                                                              (&#x27;num&#x27;,\n                                                                               StandardScaler(),\n                                                                               [&#x27;fk_score&#x27;,\n                                                                                &#x27;lexical_diversity&#x27;,\n                                                                                &#x27;average_sentence_length&#x27;,\n                                                                                &#x27;sentence_count&#x27;,\n                                                                                &#x27;average_word_length&#x27;,\n                                                                                &#x27;syllable_count&#x27;])])),\n                                             (&#x27;model&#x27;,\n                                              LogisticRegression(random_state=17))]),\n                   n_iter=5,\n                   param_distributions=[{&#x27;model__C&#x27;: [0.01, 0.1, 1, 5, 10, 30,\n                                                      50, 150],\n                                         &#x27;preprocessor__text__max_df&#x27;: array([0.7, 0.8, 0.9, 1. ]),\n                                         &#x27;preprocessor__text__max_features&#x27;: [1500,\n                                                                              3500,\n                                                                              5000,\n                                                                              8000,\n                                                                              10000],\n                                         &#x27;preprocessor__text__min_df&#x27;: array([0.1, 0.2, 0.3, 0.4])}],\n                   random_state=17, scoring=&#x27;accuracy&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3,\n                   estimator=Pipeline(steps=[(&#x27;preprocessor&#x27;,\n                                              ColumnTransformer(transformers=[(&#x27;text&#x27;,\n                                                                               CountVectorizer(ngram_range=(1,\n                                                                                                            2)),\n                                                                               &#x27;text_cleaned_lemmatization&#x27;),\n                                                                              (&#x27;num&#x27;,\n                                                                               StandardScaler(),\n                                                                               [&#x27;fk_score&#x27;,\n                                                                                &#x27;lexical_diversity&#x27;,\n                                                                                &#x27;average_sentence_length&#x27;,\n                                                                                &#x27;sentence_count&#x27;,\n                                                                                &#x27;average_word_length&#x27;,\n                                                                                &#x27;syllable_count&#x27;])])),\n                                             (&#x27;model&#x27;,\n                                              LogisticRegression(random_state=17))]),\n                   n_iter=5,\n                   param_distributions=[{&#x27;model__C&#x27;: [0.01, 0.1, 1, 5, 10, 30,\n                                                      50, 150],\n                                         &#x27;preprocessor__text__max_df&#x27;: array([0.7, 0.8, 0.9, 1. ]),\n                                         &#x27;preprocessor__text__max_features&#x27;: [1500,\n                                                                              3500,\n                                                                              5000,\n                                                                              8000,\n                                                                              10000],\n                                         &#x27;preprocessor__text__min_df&#x27;: array([0.1, 0.2, 0.3, 0.4])}],\n                   random_state=17, scoring=&#x27;accuracy&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n                 ColumnTransformer(transformers=[(&#x27;text&#x27;,\n                                                  CountVectorizer(ngram_range=(1,\n                                                                               2)),\n                                                  &#x27;text_cleaned_lemmatization&#x27;),\n                                                 (&#x27;num&#x27;, StandardScaler(),\n                                                  [&#x27;fk_score&#x27;,\n                                                   &#x27;lexical_diversity&#x27;,\n                                                   &#x27;average_sentence_length&#x27;,\n                                                   &#x27;sentence_count&#x27;,\n                                                   &#x27;average_word_length&#x27;,\n                                                   &#x27;syllable_count&#x27;])])),\n                (&#x27;model&#x27;, LogisticRegression(random_state=17))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;text&#x27;, CountVectorizer(ngram_range=(1, 2)),\n                                 &#x27;text_cleaned_lemmatization&#x27;),\n                                (&#x27;num&#x27;, StandardScaler(),\n                                 [&#x27;fk_score&#x27;, &#x27;lexical_diversity&#x27;,\n                                  &#x27;average_sentence_length&#x27;, &#x27;sentence_count&#x27;,\n                                  &#x27;average_word_length&#x27;, &#x27;syllable_count&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">text</label><div class=\"sk-toggleable__content\"><pre>text_cleaned_lemmatization</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(ngram_range=(1, 2))</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[&#x27;fk_score&#x27;, &#x27;lexical_diversity&#x27;, &#x27;average_sentence_length&#x27;, &#x27;sentence_count&#x27;, &#x27;average_word_length&#x27;, &#x27;syllable_count&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=17)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"cv_result_cols = ['param_preprocessor__text__min_df', 'param_preprocessor__text__max_features','param_preprocessor__text__max_df', \n                  'param_model__C', 'mean_test_score', 'std_test_score', 'rank_test_score']\n\nprint(f'Лучшее значение метрики: {rand_search.best_score_}')\n\n\ncv_results = pd.DataFrame(rand_search.cv_results_)[cv_result_cols].sort_values(by=['rank_test_score'])\ncv_results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T18:25:12.555610Z","iopub.execute_input":"2024-12-11T18:25:12.556019Z","iopub.status.idle":"2024-12-11T18:25:12.574586Z","shell.execute_reply.started":"2024-12-11T18:25:12.555987Z","shell.execute_reply":"2024-12-11T18:25:12.573237Z"}},"outputs":[{"name":"stdout","text":"Лучшее значение метрики: 0.652892561983471\n","output_type":"stream"},{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"  param_preprocessor__text__min_df param_preprocessor__text__max_features  \\\n3                              0.3                                   5000   \n0                              0.4                                   1500   \n2                              0.4                                   1500   \n4                              0.3                                   3500   \n1                              0.2                                   1500   \n\n  param_preprocessor__text__max_df param_model__C  mean_test_score  \\\n3                              1.0             10         0.652893   \n0                              1.0            150         0.644628   \n2                              1.0            0.1         0.633609   \n4                              0.7             30         0.559229   \n1                              0.7              5         0.534435   \n\n   std_test_score  rank_test_score  \n3        0.047235                1  \n0        0.042141                2  \n2        0.030428                3  \n4        0.047874                4  \n1        0.043383                5  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>param_preprocessor__text__min_df</th>\n      <th>param_preprocessor__text__max_features</th>\n      <th>param_preprocessor__text__max_df</th>\n      <th>param_model__C</th>\n      <th>mean_test_score</th>\n      <th>std_test_score</th>\n      <th>rank_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>0.3</td>\n      <td>5000</td>\n      <td>1.0</td>\n      <td>10</td>\n      <td>0.652893</td>\n      <td>0.047235</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.4</td>\n      <td>1500</td>\n      <td>1.0</td>\n      <td>150</td>\n      <td>0.644628</td>\n      <td>0.042141</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.4</td>\n      <td>1500</td>\n      <td>1.0</td>\n      <td>0.1</td>\n      <td>0.633609</td>\n      <td>0.030428</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.3</td>\n      <td>3500</td>\n      <td>0.7</td>\n      <td>30</td>\n      <td>0.559229</td>\n      <td>0.047874</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.2</td>\n      <td>1500</td>\n      <td>0.7</td>\n      <td>5</td>\n      <td>0.534435</td>\n      <td>0.043383</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":35},{"cell_type":"code","source":"log_reg_BoW_ngrams = rand_search.best_estimator_\n\ny_pred = log_reg_BoW_ngrams.predict(X_test)\nlog_reg_bow_ngram_metrics = metrics(y_pred, y_test)\nlog_reg_bow_ngram_metrics ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T18:25:12.576152Z","iopub.execute_input":"2024-12-11T18:25:12.576618Z","iopub.status.idle":"2024-12-11T18:25:18.813057Z","shell.execute_reply.started":"2024-12-11T18:25:12.576572Z","shell.execute_reply":"2024-12-11T18:25:18.809864Z"}},"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"              Metric     Score\n0           Accuracy  0.529412\n1  Precision (Macro)  0.410303\n2  Precision (Micro)  0.529412\n3     Recall (Macro)  0.490909\n4     Recall (Micro)  0.529412\n5   F1 Score (Macro)  0.430303\n6   F1 Score (Micro)  0.529412\n7            ROC AUC       NaN","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Metric</th>\n      <th>Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Accuracy</td>\n      <td>0.529412</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Precision (Macro)</td>\n      <td>0.410303</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Precision (Micro)</td>\n      <td>0.529412</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Recall (Macro)</td>\n      <td>0.490909</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Recall (Micro)</td>\n      <td>0.529412</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>F1 Score (Macro)</td>\n      <td>0.430303</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>F1 Score (Micro)</td>\n      <td>0.529412</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>ROC AUC</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":36},{"cell_type":"markdown","source":"### BoW + SVM","metadata":{}},{"cell_type":"markdown","source":"Теперь определим пайплайн для SVM-модели.","metadata":{}},{"cell_type":"code","source":"preprocessor = ColumnTransformer(\n    transformers = [('text', CountVectorizer(), text_feature),\n                    ('num', StandardScaler(), num_features)],\n    remainder='drop'\n)\n\n# Создание Pipeline\nSVC_classif = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('model', SVC(random_state=RANDOM_STATE))\n])\n\n\n# Определим параметры\nSVC_params =[\n    {\n     'preprocessor__text__max_df': np.arange(0.7, 1.1, 0.1),\n     'preprocessor__text__min_df': np.arange(0.1, 0.4, 0.1),  \n     'preprocessor__text__max_features': [100, 300, 500, 1000, 1500, 3500, 5000, 8000, 10000],\n     'model__C': [0.01, 0.1, 1, 5, 10, 30, 50, 150] \n    }\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T18:25:18.814690Z","iopub.execute_input":"2024-12-11T18:25:18.815178Z","iopub.status.idle":"2024-12-11T18:25:18.833908Z","shell.execute_reply.started":"2024-12-11T18:25:18.815131Z","shell.execute_reply":"2024-12-11T18:25:18.832406Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"rand_search = RandomizedSearchCV(SVC_classif, SVC_params, n_iter=10, scoring='accuracy', cv=3, verbose=3, random_state=RANDOM_STATE)\nrand_search.fit(X_train, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T18:25:18.838976Z","iopub.execute_input":"2024-12-11T18:25:18.840000Z","iopub.status.idle":"2024-12-11T18:30:14.879099Z","shell.execute_reply.started":"2024-12-11T18:25:18.839925Z","shell.execute_reply":"2024-12-11T18:30:14.877764Z"}},"outputs":[{"name":"stdout","text":"Fitting 3 folds for each of 10 candidates, totalling 30 fits\n[CV 1/3] END model__C=5, preprocessor__text__max_df=0.8999999999999999, preprocessor__text__max_features=500, preprocessor__text__min_df=0.4;, score=0.281 total time=  13.0s\n[CV 2/3] END model__C=5, preprocessor__text__max_df=0.8999999999999999, preprocessor__text__max_features=500, preprocessor__text__min_df=0.4;, score=0.504 total time=  12.9s\n[CV 3/3] END model__C=5, preprocessor__text__max_df=0.8999999999999999, preprocessor__text__max_features=500, preprocessor__text__min_df=0.4;, score=0.240 total time=  13.0s\n[CV 1/3] END model__C=150, preprocessor__text__max_df=0.7, preprocessor__text__max_features=300, preprocessor__text__min_df=0.2;, score=0.306 total time=  12.8s\n[CV 2/3] END model__C=150, preprocessor__text__max_df=0.7, preprocessor__text__max_features=300, preprocessor__text__min_df=0.2;, score=0.488 total time=  13.0s\n[CV 3/3] END model__C=150, preprocessor__text__max_df=0.7, preprocessor__text__max_features=300, preprocessor__text__min_df=0.2;, score=0.256 total time=  13.0s\n[CV 1/3] END model__C=0.01, preprocessor__text__max_df=0.9999999999999999, preprocessor__text__max_features=10000, preprocessor__text__min_df=0.4;, score=0.107 total time=  12.9s\n[CV 2/3] END model__C=0.01, preprocessor__text__max_df=0.9999999999999999, preprocessor__text__max_features=10000, preprocessor__text__min_df=0.4;, score=0.116 total time=  13.2s\n[CV 3/3] END model__C=0.01, preprocessor__text__max_df=0.9999999999999999, preprocessor__text__max_features=10000, preprocessor__text__min_df=0.4;, score=0.116 total time=  13.5s\n[CV 1/3] END model__C=150, preprocessor__text__max_df=1.0999999999999999, preprocessor__text__max_features=500, preprocessor__text__min_df=0.30000000000000004;, score=nan total time=   0.0s\n[CV 2/3] END model__C=150, preprocessor__text__max_df=1.0999999999999999, preprocessor__text__max_features=500, preprocessor__text__min_df=0.30000000000000004;, score=nan total time=   0.0s\n[CV 3/3] END model__C=150, preprocessor__text__max_df=1.0999999999999999, preprocessor__text__max_features=500, preprocessor__text__min_df=0.30000000000000004;, score=nan total time=   0.0s\n[CV 1/3] END model__C=1, preprocessor__text__max_df=0.7999999999999999, preprocessor__text__max_features=500, preprocessor__text__min_df=0.30000000000000004;, score=0.223 total time=  12.7s\n[CV 2/3] END model__C=1, preprocessor__text__max_df=0.7999999999999999, preprocessor__text__max_features=500, preprocessor__text__min_df=0.30000000000000004;, score=0.264 total time=  13.0s\n[CV 3/3] END model__C=1, preprocessor__text__max_df=0.7999999999999999, preprocessor__text__max_features=500, preprocessor__text__min_df=0.30000000000000004;, score=0.182 total time=  13.1s\n[CV 1/3] END model__C=150, preprocessor__text__max_df=0.8999999999999999, preprocessor__text__max_features=300, preprocessor__text__min_df=0.2;, score=0.322 total time=  12.8s\n[CV 2/3] END model__C=150, preprocessor__text__max_df=0.8999999999999999, preprocessor__text__max_features=300, preprocessor__text__min_df=0.2;, score=0.587 total time=  12.9s\n[CV 3/3] END model__C=150, preprocessor__text__max_df=0.8999999999999999, preprocessor__text__max_features=300, preprocessor__text__min_df=0.2;, score=0.306 total time=  12.9s\n[CV 1/3] END model__C=10, preprocessor__text__max_df=0.7, preprocessor__text__max_features=10000, preprocessor__text__min_df=0.1;, score=0.207 total time=  18.6s\n[CV 2/3] END model__C=10, preprocessor__text__max_df=0.7, preprocessor__text__max_features=10000, preprocessor__text__min_df=0.1;, score=0.488 total time=  14.3s\n[CV 3/3] END model__C=10, preprocessor__text__max_df=0.7, preprocessor__text__max_features=10000, preprocessor__text__min_df=0.1;, score=0.231 total time=  14.4s\n[CV 1/3] END model__C=0.1, preprocessor__text__max_df=0.8999999999999999, preprocessor__text__max_features=5000, preprocessor__text__min_df=0.30000000000000004;, score=0.107 total time=  13.3s\n[CV 2/3] END model__C=0.1, preprocessor__text__max_df=0.8999999999999999, preprocessor__text__max_features=5000, preprocessor__text__min_df=0.30000000000000004;, score=0.116 total time=  13.5s\n[CV 3/3] END model__C=0.1, preprocessor__text__max_df=0.8999999999999999, preprocessor__text__max_features=5000, preprocessor__text__min_df=0.30000000000000004;, score=0.116 total time=  13.4s\n[CV 1/3] END model__C=30, preprocessor__text__max_df=1.0999999999999999, preprocessor__text__max_features=500, preprocessor__text__min_df=0.4;, score=nan total time=   0.0s\n[CV 2/3] END model__C=30, preprocessor__text__max_df=1.0999999999999999, preprocessor__text__max_features=500, preprocessor__text__min_df=0.4;, score=nan total time=   0.0s\n[CV 3/3] END model__C=30, preprocessor__text__max_df=1.0999999999999999, preprocessor__text__max_features=500, preprocessor__text__min_df=0.4;, score=nan total time=   0.0s\n[CV 1/3] END model__C=0.1, preprocessor__text__max_df=1.0999999999999999, preprocessor__text__max_features=100, preprocessor__text__min_df=0.1;, score=nan total time=   0.0s\n[CV 2/3] END model__C=0.1, preprocessor__text__max_df=1.0999999999999999, preprocessor__text__max_features=100, preprocessor__text__min_df=0.1;, score=nan total time=   0.0s\n[CV 3/3] END model__C=0.1, preprocessor__text__max_df=1.0999999999999999, preprocessor__text__max_features=100, preprocessor__text__min_df=0.1;, score=nan total time=   0.0s\n","output_type":"stream"},{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"RandomizedSearchCV(cv=3,\n                   estimator=Pipeline(steps=[('preprocessor',\n                                              ColumnTransformer(transformers=[('text',\n                                                                               CountVectorizer(),\n                                                                               'text_cleaned_lemmatization'),\n                                                                              ('num',\n                                                                               StandardScaler(),\n                                                                               ['fk_score',\n                                                                                'lexical_diversity',\n                                                                                'average_sentence_length',\n                                                                                'sentence_count',\n                                                                                'average_word_length',\n                                                                                'syllable_count'])])),\n                                             ('model', SVC(random_state=17))]),\n                   param_distributions=[{'model__C': [0.01, 0.1, 1, 5, 10, 30,\n                                                      50, 150],\n                                         'preprocessor__text__max_df': array([0.7, 0.8, 0.9, 1. , 1.1]),\n                                         'preprocessor__text__max_features': [100,\n                                                                              300,\n                                                                              500,\n                                                                              1000,\n                                                                              1500,\n                                                                              3500,\n                                                                              5000,\n                                                                              8000,\n                                                                              10000],\n                                         'preprocessor__text__min_df': array([0.1, 0.2, 0.3, 0.4])}],\n                   random_state=17, scoring='accuracy', verbose=3)","text/html":"<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3,\n                   estimator=Pipeline(steps=[(&#x27;preprocessor&#x27;,\n                                              ColumnTransformer(transformers=[(&#x27;text&#x27;,\n                                                                               CountVectorizer(),\n                                                                               &#x27;text_cleaned_lemmatization&#x27;),\n                                                                              (&#x27;num&#x27;,\n                                                                               StandardScaler(),\n                                                                               [&#x27;fk_score&#x27;,\n                                                                                &#x27;lexical_diversity&#x27;,\n                                                                                &#x27;average_sentence_length&#x27;,\n                                                                                &#x27;sentence_count&#x27;,\n                                                                                &#x27;average_word_length&#x27;,\n                                                                                &#x27;syllable_count&#x27;])])),\n                                             (&#x27;model&#x27;, SVC(random_state=17))]),\n                   param_distributions=[{&#x27;model__C&#x27;: [0.01, 0.1, 1, 5, 10, 30,\n                                                      50, 150],\n                                         &#x27;preprocessor__text__max_df&#x27;: array([0.7, 0.8, 0.9, 1. , 1.1]),\n                                         &#x27;preprocessor__text__max_features&#x27;: [100,\n                                                                              300,\n                                                                              500,\n                                                                              1000,\n                                                                              1500,\n                                                                              3500,\n                                                                              5000,\n                                                                              8000,\n                                                                              10000],\n                                         &#x27;preprocessor__text__min_df&#x27;: array([0.1, 0.2, 0.3, 0.4])}],\n                   random_state=17, scoring=&#x27;accuracy&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3,\n                   estimator=Pipeline(steps=[(&#x27;preprocessor&#x27;,\n                                              ColumnTransformer(transformers=[(&#x27;text&#x27;,\n                                                                               CountVectorizer(),\n                                                                               &#x27;text_cleaned_lemmatization&#x27;),\n                                                                              (&#x27;num&#x27;,\n                                                                               StandardScaler(),\n                                                                               [&#x27;fk_score&#x27;,\n                                                                                &#x27;lexical_diversity&#x27;,\n                                                                                &#x27;average_sentence_length&#x27;,\n                                                                                &#x27;sentence_count&#x27;,\n                                                                                &#x27;average_word_length&#x27;,\n                                                                                &#x27;syllable_count&#x27;])])),\n                                             (&#x27;model&#x27;, SVC(random_state=17))]),\n                   param_distributions=[{&#x27;model__C&#x27;: [0.01, 0.1, 1, 5, 10, 30,\n                                                      50, 150],\n                                         &#x27;preprocessor__text__max_df&#x27;: array([0.7, 0.8, 0.9, 1. , 1.1]),\n                                         &#x27;preprocessor__text__max_features&#x27;: [100,\n                                                                              300,\n                                                                              500,\n                                                                              1000,\n                                                                              1500,\n                                                                              3500,\n                                                                              5000,\n                                                                              8000,\n                                                                              10000],\n                                         &#x27;preprocessor__text__min_df&#x27;: array([0.1, 0.2, 0.3, 0.4])}],\n                   random_state=17, scoring=&#x27;accuracy&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n                 ColumnTransformer(transformers=[(&#x27;text&#x27;, CountVectorizer(),\n                                                  &#x27;text_cleaned_lemmatization&#x27;),\n                                                 (&#x27;num&#x27;, StandardScaler(),\n                                                  [&#x27;fk_score&#x27;,\n                                                   &#x27;lexical_diversity&#x27;,\n                                                   &#x27;average_sentence_length&#x27;,\n                                                   &#x27;sentence_count&#x27;,\n                                                   &#x27;average_word_length&#x27;,\n                                                   &#x27;syllable_count&#x27;])])),\n                (&#x27;model&#x27;, SVC(random_state=17))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;text&#x27;, CountVectorizer(),\n                                 &#x27;text_cleaned_lemmatization&#x27;),\n                                (&#x27;num&#x27;, StandardScaler(),\n                                 [&#x27;fk_score&#x27;, &#x27;lexical_diversity&#x27;,\n                                  &#x27;average_sentence_length&#x27;, &#x27;sentence_count&#x27;,\n                                  &#x27;average_word_length&#x27;, &#x27;syllable_count&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">text</label><div class=\"sk-toggleable__content\"><pre>text_cleaned_lemmatization</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" ><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" ><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[&#x27;fk_score&#x27;, &#x27;lexical_diversity&#x27;, &#x27;average_sentence_length&#x27;, &#x27;sentence_count&#x27;, &#x27;average_word_length&#x27;, &#x27;syllable_count&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-31\" type=\"checkbox\" ><label for=\"sk-estimator-id-31\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-32\" type=\"checkbox\" ><label for=\"sk-estimator-id-32\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(random_state=17)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"},"metadata":{}}],"execution_count":38},{"cell_type":"code","source":"print(f'Лучшее значение метрики: {rand_search.best_score_}')\n\ncv_results = pd.DataFrame(rand_search.cv_results_)[cv_result_cols].sort_values(by=['rank_test_score'])\ncv_results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T18:30:14.880673Z","iopub.execute_input":"2024-12-11T18:30:14.881036Z","iopub.status.idle":"2024-12-11T18:30:14.899845Z","shell.execute_reply.started":"2024-12-11T18:30:14.881005Z","shell.execute_reply":"2024-12-11T18:30:14.898830Z"}},"outputs":[{"name":"stdout","text":"Лучшее значение метрики: 0.40495867768595045\n","output_type":"stream"},{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"  param_preprocessor__text__min_df param_preprocessor__text__max_features  \\\n5                              0.2                                    300   \n1                              0.2                                    300   \n0                              0.4                                    500   \n6                              0.1                                  10000   \n4                              0.3                                    500   \n2                              0.4                                  10000   \n7                              0.3                                   5000   \n3                              0.3                                    500   \n8                              0.4                                    500   \n9                              0.1                                    100   \n\n  param_preprocessor__text__max_df param_model__C  mean_test_score  \\\n5                              0.9            150         0.404959   \n1                              0.7            150         0.349862   \n0                              0.9              5         0.341598   \n6                              0.7             10         0.308540   \n4                              0.8              1         0.223140   \n2                              1.0           0.01         0.112948   \n7                              0.9            0.1         0.112948   \n3                              1.1            150              NaN   \n8                              1.1             30              NaN   \n9                              1.1            0.1              NaN   \n\n   std_test_score  rank_test_score  \n5        0.128742                1  \n1        0.099479                2  \n0        0.116161                3  \n6        0.127021                4  \n4        0.033740                5  \n2        0.003896                6  \n7        0.003896                6  \n3             NaN                8  \n8             NaN                8  \n9             NaN                8  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>param_preprocessor__text__min_df</th>\n      <th>param_preprocessor__text__max_features</th>\n      <th>param_preprocessor__text__max_df</th>\n      <th>param_model__C</th>\n      <th>mean_test_score</th>\n      <th>std_test_score</th>\n      <th>rank_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5</th>\n      <td>0.2</td>\n      <td>300</td>\n      <td>0.9</td>\n      <td>150</td>\n      <td>0.404959</td>\n      <td>0.128742</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.2</td>\n      <td>300</td>\n      <td>0.7</td>\n      <td>150</td>\n      <td>0.349862</td>\n      <td>0.099479</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.4</td>\n      <td>500</td>\n      <td>0.9</td>\n      <td>5</td>\n      <td>0.341598</td>\n      <td>0.116161</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.1</td>\n      <td>10000</td>\n      <td>0.7</td>\n      <td>10</td>\n      <td>0.308540</td>\n      <td>0.127021</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.3</td>\n      <td>500</td>\n      <td>0.8</td>\n      <td>1</td>\n      <td>0.223140</td>\n      <td>0.033740</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.4</td>\n      <td>10000</td>\n      <td>1.0</td>\n      <td>0.01</td>\n      <td>0.112948</td>\n      <td>0.003896</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.3</td>\n      <td>5000</td>\n      <td>0.9</td>\n      <td>0.1</td>\n      <td>0.112948</td>\n      <td>0.003896</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.3</td>\n      <td>500</td>\n      <td>1.1</td>\n      <td>150</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.4</td>\n      <td>500</td>\n      <td>1.1</td>\n      <td>30</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.1</td>\n      <td>100</td>\n      <td>1.1</td>\n      <td>0.1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>8</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":39},{"cell_type":"code","source":"best_SVC_BoW = rand_search.best_estimator_\n\ny_pred = best_SVC_BoW.predict(X_test)\n#y_pred_proba = best_SVC_BoW.predict_proba(X_test)\nsvc_bow_metrics = metrics(y_pred, y_test)\nsvc_bow_metrics","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T18:30:14.901292Z","iopub.execute_input":"2024-12-11T18:30:14.901720Z","iopub.status.idle":"2024-12-11T18:30:17.756819Z","shell.execute_reply.started":"2024-12-11T18:30:14.901673Z","shell.execute_reply":"2024-12-11T18:30:17.755688Z"}},"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"              Metric     Score\n0           Accuracy  0.490196\n1  Precision (Macro)  0.379245\n2  Precision (Micro)  0.490196\n3     Recall (Macro)  0.471698\n4     Recall (Micro)  0.490196\n5   F1 Score (Macro)  0.401903\n6   F1 Score (Micro)  0.490196\n7            ROC AUC       NaN","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Metric</th>\n      <th>Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Accuracy</td>\n      <td>0.490196</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Precision (Macro)</td>\n      <td>0.379245</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Precision (Micro)</td>\n      <td>0.490196</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Recall (Macro)</td>\n      <td>0.471698</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Recall (Micro)</td>\n      <td>0.490196</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>F1 Score (Macro)</td>\n      <td>0.401903</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>F1 Score (Micro)</td>\n      <td>0.490196</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>ROC AUC</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":40},{"cell_type":"markdown","source":"### tfidf + SVM","metadata":{}},{"cell_type":"code","source":"preprocessor = ColumnTransformer(\n    transformers = [('text',TfidfVectorizer(), text_feature),\n                    ('num', StandardScaler(), num_features)],\n    remainder='drop'\n)\n\n# Создание Pipeline\nSVC_classif = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('model', SVC(random_state=RANDOM_STATE))\n])\n\n\n# Определим параметры\nSVC_params =[\n    {\n     'preprocessor__text__max_df': np.arange(0.7, 1.1, 0.1),\n     'preprocessor__text__min_df': np.arange(0.1, 0.4, 0.1),  \n     'preprocessor__text__max_features': [300, 500, 1000, 1500, 3500, 5000, 8000],\n     'model__C': [0.01, 0.1, 1, 5, 10, 30, 50, 150] \n    }\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T18:30:17.758935Z","iopub.execute_input":"2024-12-11T18:30:17.759386Z","iopub.status.idle":"2024-12-11T18:30:17.766436Z","shell.execute_reply.started":"2024-12-11T18:30:17.759339Z","shell.execute_reply":"2024-12-11T18:30:17.765213Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"rand_search = RandomizedSearchCV(SVC_classif, SVC_params, n_iter=10, scoring='accuracy', cv=3, verbose=3, random_state=RANDOM_STATE)\nrand_search.fit(X_train, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T18:30:17.768033Z","iopub.execute_input":"2024-12-11T18:30:17.768377Z","iopub.status.idle":"2024-12-11T18:35:52.592314Z","shell.execute_reply.started":"2024-12-11T18:30:17.768346Z","shell.execute_reply":"2024-12-11T18:35:52.591211Z"}},"outputs":[{"name":"stdout","text":"Fitting 3 folds for each of 10 candidates, totalling 30 fits\n[CV 1/3] END model__C=10, preprocessor__text__max_df=0.8999999999999999, preprocessor__text__max_features=500, preprocessor__text__min_df=0.4;, score=0.273 total time=  12.9s\n[CV 2/3] END model__C=10, preprocessor__text__max_df=0.8999999999999999, preprocessor__text__max_features=500, preprocessor__text__min_df=0.4;, score=0.529 total time=  13.1s\n[CV 3/3] END model__C=10, preprocessor__text__max_df=0.8999999999999999, preprocessor__text__max_features=500, preprocessor__text__min_df=0.4;, score=0.397 total time=  13.5s\n[CV 1/3] END model__C=0.1, preprocessor__text__max_df=0.7, preprocessor__text__max_features=300, preprocessor__text__min_df=0.4;, score=0.140 total time=  12.7s\n[CV 2/3] END model__C=0.1, preprocessor__text__max_df=0.7, preprocessor__text__max_features=300, preprocessor__text__min_df=0.4;, score=0.132 total time=  13.3s\n[CV 3/3] END model__C=0.1, preprocessor__text__max_df=0.7, preprocessor__text__max_features=300, preprocessor__text__min_df=0.4;, score=0.157 total time=  13.1s\n[CV 1/3] END model__C=1, preprocessor__text__max_df=1.0999999999999999, preprocessor__text__max_features=1500, preprocessor__text__min_df=0.30000000000000004;, score=nan total time=   0.0s\n[CV 2/3] END model__C=1, preprocessor__text__max_df=1.0999999999999999, preprocessor__text__max_features=1500, preprocessor__text__min_df=0.30000000000000004;, score=nan total time=   0.0s\n[CV 3/3] END model__C=1, preprocessor__text__max_df=1.0999999999999999, preprocessor__text__max_features=1500, preprocessor__text__min_df=0.30000000000000004;, score=nan total time=   0.0s\n[CV 1/3] END model__C=30, preprocessor__text__max_df=0.7999999999999999, preprocessor__text__max_features=8000, preprocessor__text__min_df=0.1;, score=0.298 total time=  14.1s\n[CV 2/3] END model__C=30, preprocessor__text__max_df=0.7999999999999999, preprocessor__text__max_features=8000, preprocessor__text__min_df=0.1;, score=0.512 total time=  14.1s\n[CV 3/3] END model__C=30, preprocessor__text__max_df=0.7999999999999999, preprocessor__text__max_features=8000, preprocessor__text__min_df=0.1;, score=0.331 total time=  14.1s\n[CV 1/3] END model__C=0.1, preprocessor__text__max_df=1.0999999999999999, preprocessor__text__max_features=8000, preprocessor__text__min_df=0.30000000000000004;, score=nan total time=   0.0s\n[CV 2/3] END model__C=0.1, preprocessor__text__max_df=1.0999999999999999, preprocessor__text__max_features=8000, preprocessor__text__min_df=0.30000000000000004;, score=nan total time=   0.0s\n[CV 3/3] END model__C=0.1, preprocessor__text__max_df=1.0999999999999999, preprocessor__text__max_features=8000, preprocessor__text__min_df=0.30000000000000004;, score=nan total time=   0.0s\n[CV 1/3] END model__C=150, preprocessor__text__max_df=0.8999999999999999, preprocessor__text__max_features=3500, preprocessor__text__min_df=0.4;, score=0.289 total time=  13.3s\n[CV 2/3] END model__C=150, preprocessor__text__max_df=0.8999999999999999, preprocessor__text__max_features=3500, preprocessor__text__min_df=0.4;, score=0.504 total time=  13.5s\n[CV 3/3] END model__C=150, preprocessor__text__max_df=0.8999999999999999, preprocessor__text__max_features=3500, preprocessor__text__min_df=0.4;, score=0.347 total time=  13.7s\n[CV 1/3] END model__C=1, preprocessor__text__max_df=0.7999999999999999, preprocessor__text__max_features=3500, preprocessor__text__min_df=0.1;, score=0.165 total time=  13.4s\n[CV 2/3] END model__C=1, preprocessor__text__max_df=0.7999999999999999, preprocessor__text__max_features=3500, preprocessor__text__min_df=0.1;, score=0.372 total time=  13.6s\n[CV 3/3] END model__C=1, preprocessor__text__max_df=0.7999999999999999, preprocessor__text__max_features=3500, preprocessor__text__min_df=0.1;, score=0.223 total time=  13.5s\n[CV 1/3] END model__C=5, preprocessor__text__max_df=0.7999999999999999, preprocessor__text__max_features=5000, preprocessor__text__min_df=0.1;, score=0.289 total time=  13.6s\n[CV 2/3] END model__C=5, preprocessor__text__max_df=0.7999999999999999, preprocessor__text__max_features=5000, preprocessor__text__min_df=0.1;, score=0.504 total time=  13.9s\n[CV 3/3] END model__C=5, preprocessor__text__max_df=0.7999999999999999, preprocessor__text__max_features=5000, preprocessor__text__min_df=0.1;, score=0.322 total time=  13.6s\n[CV 1/3] END model__C=50, preprocessor__text__max_df=0.8999999999999999, preprocessor__text__max_features=300, preprocessor__text__min_df=0.2;, score=0.298 total time=  12.8s\n[CV 2/3] END model__C=50, preprocessor__text__max_df=0.8999999999999999, preprocessor__text__max_features=300, preprocessor__text__min_df=0.2;, score=0.521 total time=  13.0s\n[CV 3/3] END model__C=50, preprocessor__text__max_df=0.8999999999999999, preprocessor__text__max_features=300, preprocessor__text__min_df=0.2;, score=0.372 total time=  13.2s\n[CV 1/3] END model__C=150, preprocessor__text__max_df=0.8999999999999999, preprocessor__text__max_features=500, preprocessor__text__min_df=0.2;, score=0.273 total time=  12.9s\n[CV 2/3] END model__C=150, preprocessor__text__max_df=0.8999999999999999, preprocessor__text__max_features=500, preprocessor__text__min_df=0.2;, score=0.529 total time=  13.0s\n[CV 3/3] END model__C=150, preprocessor__text__max_df=0.8999999999999999, preprocessor__text__max_features=500, preprocessor__text__min_df=0.2;, score=0.380 total time=  13.1s\n","output_type":"stream"},{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"RandomizedSearchCV(cv=3,\n                   estimator=Pipeline(steps=[('preprocessor',\n                                              ColumnTransformer(transformers=[('text',\n                                                                               TfidfVectorizer(),\n                                                                               'text_cleaned_lemmatization'),\n                                                                              ('num',\n                                                                               StandardScaler(),\n                                                                               ['fk_score',\n                                                                                'lexical_diversity',\n                                                                                'average_sentence_length',\n                                                                                'sentence_count',\n                                                                                'average_word_length',\n                                                                                'syllable_count'])])),\n                                             ('model', SVC(random_state=17))]),\n                   param_distributions=[{'model__C': [0.01, 0.1, 1, 5, 10, 30,\n                                                      50, 150],\n                                         'preprocessor__text__max_df': array([0.7, 0.8, 0.9, 1. , 1.1]),\n                                         'preprocessor__text__max_features': [300,\n                                                                              500,\n                                                                              1000,\n                                                                              1500,\n                                                                              3500,\n                                                                              5000,\n                                                                              8000],\n                                         'preprocessor__text__min_df': array([0.1, 0.2, 0.3, 0.4])}],\n                   random_state=17, scoring='accuracy', verbose=3)","text/html":"<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3,\n                   estimator=Pipeline(steps=[(&#x27;preprocessor&#x27;,\n                                              ColumnTransformer(transformers=[(&#x27;text&#x27;,\n                                                                               TfidfVectorizer(),\n                                                                               &#x27;text_cleaned_lemmatization&#x27;),\n                                                                              (&#x27;num&#x27;,\n                                                                               StandardScaler(),\n                                                                               [&#x27;fk_score&#x27;,\n                                                                                &#x27;lexical_diversity&#x27;,\n                                                                                &#x27;average_sentence_length&#x27;,\n                                                                                &#x27;sentence_count&#x27;,\n                                                                                &#x27;average_word_length&#x27;,\n                                                                                &#x27;syllable_count&#x27;])])),\n                                             (&#x27;model&#x27;, SVC(random_state=17))]),\n                   param_distributions=[{&#x27;model__C&#x27;: [0.01, 0.1, 1, 5, 10, 30,\n                                                      50, 150],\n                                         &#x27;preprocessor__text__max_df&#x27;: array([0.7, 0.8, 0.9, 1. , 1.1]),\n                                         &#x27;preprocessor__text__max_features&#x27;: [300,\n                                                                              500,\n                                                                              1000,\n                                                                              1500,\n                                                                              3500,\n                                                                              5000,\n                                                                              8000],\n                                         &#x27;preprocessor__text__min_df&#x27;: array([0.1, 0.2, 0.3, 0.4])}],\n                   random_state=17, scoring=&#x27;accuracy&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-33\" type=\"checkbox\" ><label for=\"sk-estimator-id-33\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3,\n                   estimator=Pipeline(steps=[(&#x27;preprocessor&#x27;,\n                                              ColumnTransformer(transformers=[(&#x27;text&#x27;,\n                                                                               TfidfVectorizer(),\n                                                                               &#x27;text_cleaned_lemmatization&#x27;),\n                                                                              (&#x27;num&#x27;,\n                                                                               StandardScaler(),\n                                                                               [&#x27;fk_score&#x27;,\n                                                                                &#x27;lexical_diversity&#x27;,\n                                                                                &#x27;average_sentence_length&#x27;,\n                                                                                &#x27;sentence_count&#x27;,\n                                                                                &#x27;average_word_length&#x27;,\n                                                                                &#x27;syllable_count&#x27;])])),\n                                             (&#x27;model&#x27;, SVC(random_state=17))]),\n                   param_distributions=[{&#x27;model__C&#x27;: [0.01, 0.1, 1, 5, 10, 30,\n                                                      50, 150],\n                                         &#x27;preprocessor__text__max_df&#x27;: array([0.7, 0.8, 0.9, 1. , 1.1]),\n                                         &#x27;preprocessor__text__max_features&#x27;: [300,\n                                                                              500,\n                                                                              1000,\n                                                                              1500,\n                                                                              3500,\n                                                                              5000,\n                                                                              8000],\n                                         &#x27;preprocessor__text__min_df&#x27;: array([0.1, 0.2, 0.3, 0.4])}],\n                   random_state=17, scoring=&#x27;accuracy&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-34\" type=\"checkbox\" ><label for=\"sk-estimator-id-34\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n                 ColumnTransformer(transformers=[(&#x27;text&#x27;, TfidfVectorizer(),\n                                                  &#x27;text_cleaned_lemmatization&#x27;),\n                                                 (&#x27;num&#x27;, StandardScaler(),\n                                                  [&#x27;fk_score&#x27;,\n                                                   &#x27;lexical_diversity&#x27;,\n                                                   &#x27;average_sentence_length&#x27;,\n                                                   &#x27;sentence_count&#x27;,\n                                                   &#x27;average_word_length&#x27;,\n                                                   &#x27;syllable_count&#x27;])])),\n                (&#x27;model&#x27;, SVC(random_state=17))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-35\" type=\"checkbox\" ><label for=\"sk-estimator-id-35\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;text&#x27;, TfidfVectorizer(),\n                                 &#x27;text_cleaned_lemmatization&#x27;),\n                                (&#x27;num&#x27;, StandardScaler(),\n                                 [&#x27;fk_score&#x27;, &#x27;lexical_diversity&#x27;,\n                                  &#x27;average_sentence_length&#x27;, &#x27;sentence_count&#x27;,\n                                  &#x27;average_word_length&#x27;, &#x27;syllable_count&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-36\" type=\"checkbox\" ><label for=\"sk-estimator-id-36\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">text</label><div class=\"sk-toggleable__content\"><pre>text_cleaned_lemmatization</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-37\" type=\"checkbox\" ><label for=\"sk-estimator-id-37\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-38\" type=\"checkbox\" ><label for=\"sk-estimator-id-38\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[&#x27;fk_score&#x27;, &#x27;lexical_diversity&#x27;, &#x27;average_sentence_length&#x27;, &#x27;sentence_count&#x27;, &#x27;average_word_length&#x27;, &#x27;syllable_count&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-39\" type=\"checkbox\" ><label for=\"sk-estimator-id-39\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-40\" type=\"checkbox\" ><label for=\"sk-estimator-id-40\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(random_state=17)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"},"metadata":{}}],"execution_count":42},{"cell_type":"code","source":"print(f'Лучшее значение метрики: {rand_search.best_score_}')\n\ncv_results = pd.DataFrame(rand_search.cv_results_)[cv_result_cols].sort_values(by=['rank_test_score'])\ncv_results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T18:35:52.593957Z","iopub.execute_input":"2024-12-11T18:35:52.594409Z","iopub.status.idle":"2024-12-11T18:35:52.613342Z","shell.execute_reply.started":"2024-12-11T18:35:52.594360Z","shell.execute_reply":"2024-12-11T18:35:52.612178Z"}},"outputs":[{"name":"stdout","text":"Лучшее значение метрики: 0.39944903581267216\n","output_type":"stream"},{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"  param_preprocessor__text__min_df param_preprocessor__text__max_features  \\\n0                              0.4                                    500   \n8                              0.2                                    300   \n9                              0.2                                    500   \n3                              0.1                                   8000   \n5                              0.4                                   3500   \n7                              0.1                                   5000   \n6                              0.1                                   3500   \n1                              0.4                                    300   \n2                              0.3                                   1500   \n4                              0.3                                   8000   \n\n  param_preprocessor__text__max_df param_model__C  mean_test_score  \\\n0                              0.9             10         0.399449   \n8                              0.9             50         0.396694   \n9                              0.9            150         0.393939   \n3                              0.8             30         0.380165   \n5                              0.9            150         0.380165   \n7                              0.8              5         0.371901   \n6                              0.8              1         0.253444   \n1                              0.7            0.1         0.143251   \n2                              1.1              1              NaN   \n4                              1.1            0.1              NaN   \n\n   std_test_score  rank_test_score  \n0        0.104611                1  \n8        0.092768                2  \n9        0.105045                3  \n3        0.094471                4  \n5        0.090784                4  \n7        0.094471                6  \n6        0.087028                7  \n1        0.010308                8  \n2             NaN                9  \n4             NaN                9  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>param_preprocessor__text__min_df</th>\n      <th>param_preprocessor__text__max_features</th>\n      <th>param_preprocessor__text__max_df</th>\n      <th>param_model__C</th>\n      <th>mean_test_score</th>\n      <th>std_test_score</th>\n      <th>rank_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.4</td>\n      <td>500</td>\n      <td>0.9</td>\n      <td>10</td>\n      <td>0.399449</td>\n      <td>0.104611</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.2</td>\n      <td>300</td>\n      <td>0.9</td>\n      <td>50</td>\n      <td>0.396694</td>\n      <td>0.092768</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.2</td>\n      <td>500</td>\n      <td>0.9</td>\n      <td>150</td>\n      <td>0.393939</td>\n      <td>0.105045</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.1</td>\n      <td>8000</td>\n      <td>0.8</td>\n      <td>30</td>\n      <td>0.380165</td>\n      <td>0.094471</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.4</td>\n      <td>3500</td>\n      <td>0.9</td>\n      <td>150</td>\n      <td>0.380165</td>\n      <td>0.090784</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.1</td>\n      <td>5000</td>\n      <td>0.8</td>\n      <td>5</td>\n      <td>0.371901</td>\n      <td>0.094471</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.1</td>\n      <td>3500</td>\n      <td>0.8</td>\n      <td>1</td>\n      <td>0.253444</td>\n      <td>0.087028</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.4</td>\n      <td>300</td>\n      <td>0.7</td>\n      <td>0.1</td>\n      <td>0.143251</td>\n      <td>0.010308</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.3</td>\n      <td>1500</td>\n      <td>1.1</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.3</td>\n      <td>8000</td>\n      <td>1.1</td>\n      <td>0.1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>9</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":43},{"cell_type":"code","source":"best_SVM_tfidf = rand_search.best_estimator_\n\ny_pred = best_SVM_tfidf.predict(X_test)\n#y_pred_proba = best_SVM_tfidf.predict_proba(X_test)\nSVM_tfidf_metrics = metrics(y_pred, y_test)\nSVM_tfidf_metrics ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T18:35:52.614891Z","iopub.execute_input":"2024-12-11T18:35:52.615310Z","iopub.status.idle":"2024-12-11T18:35:55.453837Z","shell.execute_reply.started":"2024-12-11T18:35:52.615262Z","shell.execute_reply":"2024-12-11T18:35:55.452715Z"}},"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"              Metric     Score\n0           Accuracy  0.509804\n1  Precision (Macro)  0.400744\n2  Precision (Micro)  0.509804\n3     Recall (Macro)  0.472727\n4     Recall (Micro)  0.509804\n5   F1 Score (Macro)  0.416364\n6   F1 Score (Micro)  0.509804\n7            ROC AUC       NaN","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Metric</th>\n      <th>Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Accuracy</td>\n      <td>0.509804</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Precision (Macro)</td>\n      <td>0.400744</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Precision (Micro)</td>\n      <td>0.509804</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Recall (Macro)</td>\n      <td>0.472727</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Recall (Micro)</td>\n      <td>0.509804</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>F1 Score (Macro)</td>\n      <td>0.416364</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>F1 Score (Micro)</td>\n      <td>0.509804</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>ROC AUC</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":44},{"cell_type":"markdown","source":"### bigrams BoW + MultinominalNB","metadata":{}},{"cell_type":"code","source":"preprocessor = ColumnTransformer(\n    transformers = [('text', CountVectorizer(ngram_range=(1,2)), text_feature),\n                    ('num', MinMaxScaler(), num_features)],\n    remainder='drop'\n)\n\n# Создание Pipeline\nnaive_bayes_classifier = Pipeline(steps=[\n                                 ('preprocessor', preprocessor),\n                                 ('model', MultinomialNB())\n])\n\n\n# Определим параметры\nnaive_bayes_params =[\n    {\n     'preprocessor__text__max_df': np.arange(0.6, 0.8, 0.1),\n     'preprocessor__text__min_df': np.arange(0.05, 0.4, 0.1),  \n     'preprocessor__text__max_features': [500, 1000, 1500, 3500],\n    }\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T18:35:55.455211Z","iopub.execute_input":"2024-12-11T18:35:55.455653Z","iopub.status.idle":"2024-12-11T18:35:55.463496Z","shell.execute_reply.started":"2024-12-11T18:35:55.455593Z","shell.execute_reply":"2024-12-11T18:35:55.462311Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"rand_search = RandomizedSearchCV(naive_bayes_classifier, naive_bayes_params, n_iter=5, scoring='accuracy', cv=3, verbose=3, random_state=RANDOM_STATE)\nrand_search.fit(X_train, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T18:35:55.465030Z","iopub.execute_input":"2024-12-11T18:35:55.465480Z","iopub.status.idle":"2024-12-11T18:52:40.173356Z","shell.execute_reply.started":"2024-12-11T18:35:55.465433Z","shell.execute_reply":"2024-12-11T18:52:40.171712Z"}},"outputs":[{"name":"stdout","text":"Fitting 3 folds for each of 5 candidates, totalling 15 fits\n[CV 1/3] END preprocessor__text__max_df=0.7999999999999999, preprocessor__text__max_features=3500, preprocessor__text__min_df=0.25000000000000006;, score=0.711 total time=  50.5s\n[CV 2/3] END preprocessor__text__max_df=0.7999999999999999, preprocessor__text__max_features=3500, preprocessor__text__min_df=0.25000000000000006;, score=0.719 total time= 1.0min\n[CV 3/3] END preprocessor__text__max_df=0.7999999999999999, preprocessor__text__max_features=3500, preprocessor__text__min_df=0.25000000000000006;, score=0.702 total time= 1.1min\n[CV 1/3] END preprocessor__text__max_df=0.7999999999999999, preprocessor__text__max_features=1500, preprocessor__text__min_df=0.05;, score=0.645 total time=  49.5s\n[CV 2/3] END preprocessor__text__max_df=0.7999999999999999, preprocessor__text__max_features=1500, preprocessor__text__min_df=0.05;, score=0.711 total time= 1.0min\n[CV 3/3] END preprocessor__text__max_df=0.7999999999999999, preprocessor__text__max_features=1500, preprocessor__text__min_df=0.05;, score=0.661 total time= 1.1min\n[CV 1/3] END preprocessor__text__max_df=0.7, preprocessor__text__max_features=500, preprocessor__text__min_df=0.05;, score=0.603 total time=  49.7s\n[CV 2/3] END preprocessor__text__max_df=0.7, preprocessor__text__max_features=500, preprocessor__text__min_df=0.05;, score=0.653 total time= 1.1min\n[CV 3/3] END preprocessor__text__max_df=0.7, preprocessor__text__max_features=500, preprocessor__text__min_df=0.05;, score=0.537 total time= 1.1min\n[CV 1/3] END preprocessor__text__max_df=0.7, preprocessor__text__max_features=3500, preprocessor__text__min_df=0.15000000000000002;, score=0.686 total time=  49.7s\n[CV 2/3] END preprocessor__text__max_df=0.7, preprocessor__text__max_features=3500, preprocessor__text__min_df=0.15000000000000002;, score=0.719 total time= 1.0min\n[CV 3/3] END preprocessor__text__max_df=0.7, preprocessor__text__max_features=3500, preprocessor__text__min_df=0.15000000000000002;, score=0.694 total time= 1.1min\n[CV 1/3] END preprocessor__text__max_df=0.7, preprocessor__text__max_features=1000, preprocessor__text__min_df=0.15000000000000002;, score=0.628 total time=  48.9s\n[CV 2/3] END preprocessor__text__max_df=0.7, preprocessor__text__max_features=1000, preprocessor__text__min_df=0.15000000000000002;, score=0.686 total time= 1.2min\n[CV 3/3] END preprocessor__text__max_df=0.7, preprocessor__text__max_features=1000, preprocessor__text__min_df=0.15000000000000002;, score=0.595 total time= 1.2min\n","output_type":"stream"},{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"RandomizedSearchCV(cv=3,\n                   estimator=Pipeline(steps=[('preprocessor',\n                                              ColumnTransformer(transformers=[('text',\n                                                                               CountVectorizer(ngram_range=(1,\n                                                                                                            2)),\n                                                                               'text_cleaned_lemmatization'),\n                                                                              ('num',\n                                                                               MinMaxScaler(),\n                                                                               ['fk_score',\n                                                                                'lexical_diversity',\n                                                                                'average_sentence_length',\n                                                                                'sentence_count',\n                                                                                'average_word_length',\n                                                                                'syllable_count'])])),\n                                             ('model', MultinomialNB())]),\n                   n_iter=5,\n                   param_distributions=[{'preprocessor__text__max_df': array([0.6, 0.7, 0.8]),\n                                         'preprocessor__text__max_features': [500,\n                                                                              1000,\n                                                                              1500,\n                                                                              3500],\n                                         'preprocessor__text__min_df': array([0.05, 0.15, 0.25, 0.35])}],\n                   random_state=17, scoring='accuracy', verbose=3)","text/html":"<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3,\n                   estimator=Pipeline(steps=[(&#x27;preprocessor&#x27;,\n                                              ColumnTransformer(transformers=[(&#x27;text&#x27;,\n                                                                               CountVectorizer(ngram_range=(1,\n                                                                                                            2)),\n                                                                               &#x27;text_cleaned_lemmatization&#x27;),\n                                                                              (&#x27;num&#x27;,\n                                                                               MinMaxScaler(),\n                                                                               [&#x27;fk_score&#x27;,\n                                                                                &#x27;lexical_diversity&#x27;,\n                                                                                &#x27;average_sentence_length&#x27;,\n                                                                                &#x27;sentence_count&#x27;,\n                                                                                &#x27;average_word_length&#x27;,\n                                                                                &#x27;syllable_count&#x27;])])),\n                                             (&#x27;model&#x27;, MultinomialNB())]),\n                   n_iter=5,\n                   param_distributions=[{&#x27;preprocessor__text__max_df&#x27;: array([0.6, 0.7, 0.8]),\n                                         &#x27;preprocessor__text__max_features&#x27;: [500,\n                                                                              1000,\n                                                                              1500,\n                                                                              3500],\n                                         &#x27;preprocessor__text__min_df&#x27;: array([0.05, 0.15, 0.25, 0.35])}],\n                   random_state=17, scoring=&#x27;accuracy&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-41\" type=\"checkbox\" ><label for=\"sk-estimator-id-41\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3,\n                   estimator=Pipeline(steps=[(&#x27;preprocessor&#x27;,\n                                              ColumnTransformer(transformers=[(&#x27;text&#x27;,\n                                                                               CountVectorizer(ngram_range=(1,\n                                                                                                            2)),\n                                                                               &#x27;text_cleaned_lemmatization&#x27;),\n                                                                              (&#x27;num&#x27;,\n                                                                               MinMaxScaler(),\n                                                                               [&#x27;fk_score&#x27;,\n                                                                                &#x27;lexical_diversity&#x27;,\n                                                                                &#x27;average_sentence_length&#x27;,\n                                                                                &#x27;sentence_count&#x27;,\n                                                                                &#x27;average_word_length&#x27;,\n                                                                                &#x27;syllable_count&#x27;])])),\n                                             (&#x27;model&#x27;, MultinomialNB())]),\n                   n_iter=5,\n                   param_distributions=[{&#x27;preprocessor__text__max_df&#x27;: array([0.6, 0.7, 0.8]),\n                                         &#x27;preprocessor__text__max_features&#x27;: [500,\n                                                                              1000,\n                                                                              1500,\n                                                                              3500],\n                                         &#x27;preprocessor__text__min_df&#x27;: array([0.05, 0.15, 0.25, 0.35])}],\n                   random_state=17, scoring=&#x27;accuracy&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-42\" type=\"checkbox\" ><label for=\"sk-estimator-id-42\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n                 ColumnTransformer(transformers=[(&#x27;text&#x27;,\n                                                  CountVectorizer(ngram_range=(1,\n                                                                               2)),\n                                                  &#x27;text_cleaned_lemmatization&#x27;),\n                                                 (&#x27;num&#x27;, MinMaxScaler(),\n                                                  [&#x27;fk_score&#x27;,\n                                                   &#x27;lexical_diversity&#x27;,\n                                                   &#x27;average_sentence_length&#x27;,\n                                                   &#x27;sentence_count&#x27;,\n                                                   &#x27;average_word_length&#x27;,\n                                                   &#x27;syllable_count&#x27;])])),\n                (&#x27;model&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-43\" type=\"checkbox\" ><label for=\"sk-estimator-id-43\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;text&#x27;, CountVectorizer(ngram_range=(1, 2)),\n                                 &#x27;text_cleaned_lemmatization&#x27;),\n                                (&#x27;num&#x27;, MinMaxScaler(),\n                                 [&#x27;fk_score&#x27;, &#x27;lexical_diversity&#x27;,\n                                  &#x27;average_sentence_length&#x27;, &#x27;sentence_count&#x27;,\n                                  &#x27;average_word_length&#x27;, &#x27;syllable_count&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-44\" type=\"checkbox\" ><label for=\"sk-estimator-id-44\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">text</label><div class=\"sk-toggleable__content\"><pre>text_cleaned_lemmatization</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-45\" type=\"checkbox\" ><label for=\"sk-estimator-id-45\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(ngram_range=(1, 2))</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-46\" type=\"checkbox\" ><label for=\"sk-estimator-id-46\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[&#x27;fk_score&#x27;, &#x27;lexical_diversity&#x27;, &#x27;average_sentence_length&#x27;, &#x27;sentence_count&#x27;, &#x27;average_word_length&#x27;, &#x27;syllable_count&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-47\" type=\"checkbox\" ><label for=\"sk-estimator-id-47\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-48\" type=\"checkbox\" ><label for=\"sk-estimator-id-48\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"},"metadata":{}}],"execution_count":46},{"cell_type":"code","source":"print(f'Лучшее значение метрики: {rand_search.best_score_}')\ncv_result_cols = ['param_preprocessor__text__min_df', 'param_preprocessor__text__max_features', 'param_preprocessor__text__max_df', 'mean_test_score', 'std_test_score', 'rank_test_score']\n\ncv_results = pd.DataFrame(rand_search.cv_results_)[cv_result_cols].sort_values(by=['rank_test_score'])\ncv_results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T18:52:40.175932Z","iopub.execute_input":"2024-12-11T18:52:40.176464Z","iopub.status.idle":"2024-12-11T18:52:40.199503Z","shell.execute_reply.started":"2024-12-11T18:52:40.176403Z","shell.execute_reply":"2024-12-11T18:52:40.198541Z"}},"outputs":[{"name":"stdout","text":"Лучшее значение метрики: 0.7107438016528925\n","output_type":"stream"},{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"  param_preprocessor__text__min_df param_preprocessor__text__max_features  \\\n0                             0.25                                   3500   \n3                             0.15                                   3500   \n1                             0.05                                   1500   \n4                             0.15                                   1000   \n2                             0.05                                    500   \n\n  param_preprocessor__text__max_df  mean_test_score  std_test_score  \\\n0                              0.8         0.710744        0.006748   \n3                              0.7         0.699725        0.014047   \n1                              0.8         0.672176        0.028094   \n4                              0.7         0.636364        0.037571   \n2                              0.7         0.597796        0.047396   \n\n   rank_test_score  \n0                1  \n3                2  \n1                3  \n4                4  \n2                5  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>param_preprocessor__text__min_df</th>\n      <th>param_preprocessor__text__max_features</th>\n      <th>param_preprocessor__text__max_df</th>\n      <th>mean_test_score</th>\n      <th>std_test_score</th>\n      <th>rank_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.25</td>\n      <td>3500</td>\n      <td>0.8</td>\n      <td>0.710744</td>\n      <td>0.006748</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.15</td>\n      <td>3500</td>\n      <td>0.7</td>\n      <td>0.699725</td>\n      <td>0.014047</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.05</td>\n      <td>1500</td>\n      <td>0.8</td>\n      <td>0.672176</td>\n      <td>0.028094</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.15</td>\n      <td>1000</td>\n      <td>0.7</td>\n      <td>0.636364</td>\n      <td>0.037571</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.05</td>\n      <td>500</td>\n      <td>0.7</td>\n      <td>0.597796</td>\n      <td>0.047396</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":47},{"cell_type":"code","source":"naive_bayes_BoW = rand_search.best_estimator_\n\ny_pred = naive_bayes_BoW.predict(X_test)\n#y_pred_proba = naive_bayes_BoW.predict_proba(X_test)\nnaive_bayes_BoW_metrics = metrics(y_pred, y_test)\nnaive_bayes_BoW_metrics ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T18:52:40.200801Z","iopub.execute_input":"2024-12-11T18:52:40.201369Z","iopub.status.idle":"2024-12-11T18:52:46.450093Z","shell.execute_reply.started":"2024-12-11T18:52:40.201325Z","shell.execute_reply":"2024-12-11T18:52:46.447330Z"}},"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"              Metric     Score\n0           Accuracy  0.647059\n1  Precision (Macro)  0.505747\n2  Precision (Micro)  0.647059\n3     Recall (Macro)  0.568966\n4     Recall (Micro)  0.647059\n5   F1 Score (Macro)  0.525862\n6   F1 Score (Micro)  0.647059\n7            ROC AUC       NaN","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Metric</th>\n      <th>Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Accuracy</td>\n      <td>0.647059</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Precision (Macro)</td>\n      <td>0.505747</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Precision (Micro)</td>\n      <td>0.647059</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Recall (Macro)</td>\n      <td>0.568966</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Recall (Micro)</td>\n      <td>0.647059</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>F1 Score (Macro)</td>\n      <td>0.525862</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>F1 Score (Micro)</td>\n      <td>0.647059</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>ROC AUC</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":48},{"cell_type":"markdown","source":"### Эмбеддинги Word2Vec и GloVe вместе с простыми моделями","metadata":{}},{"cell_type":"markdown","source":"#### Word2Vec + LogReg","metadata":{}},{"cell_type":"code","source":"class Word2VecVectorizer(BaseEstimator, TransformerMixin):\n    def __init__(self, model):\n        self.model = model\n\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        vecs = []\n        for text in X:\n            word_vecs = [self.model.wv[word] for word in text.split() if word in self.model.wv]\n            text_vector = np.mean(word_vecs, axis=0) if word_vecs else np.zeros(self.model.vector_size)\n            vecs.append(text_vector)\n        return np.array(vecs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T18:52:46.451911Z","iopub.execute_input":"2024-12-11T18:52:46.452551Z","iopub.status.idle":"2024-12-11T18:52:46.470628Z","shell.execute_reply.started":"2024-12-11T18:52:46.452485Z","shell.execute_reply":"2024-12-11T18:52:46.469301Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"y_train.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T18:52:46.472332Z","iopub.execute_input":"2024-12-11T18:52:46.476183Z","iopub.status.idle":"2024-12-11T18:52:46.494573Z","shell.execute_reply.started":"2024-12-11T18:52:46.476099Z","shell.execute_reply":"2024-12-11T18:52:46.490964Z"}},"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"(363,)"},"metadata":{}}],"execution_count":50},{"cell_type":"code","source":"model_w2v = Word2Vec(sentences=X_train['text_cleaned_words'], vector_size=100, window=5, min_count=1)\n\npreprocessor = ColumnTransformer(\n    transformers = [('text', Word2VecVectorizer(model_w2v), text_feature),\n                    ('num', StandardScaler(), num_features)],\n    remainder='drop'\n)\n\n\nlog_reg_w2v = Pipeline([\n    ('preprocessor', preprocessor),\n    ('classifier', LogisticRegression())\n])\n\n\n\nlog_reg_w2v.fit(X_train, y_train)\n\ny_pred = log_reg_w2v.predict(X_test)\nmetrics_w2v_log_reg = metrics(y_pred, y_test)\nmetrics_w2v_log_reg","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T18:52:46.496761Z","iopub.execute_input":"2024-12-11T18:52:46.497498Z","iopub.status.idle":"2024-12-11T18:54:02.370216Z","shell.execute_reply.started":"2024-12-11T18:52:46.497447Z","shell.execute_reply":"2024-12-11T18:54:02.367487Z"}},"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"              Metric     Score\n0           Accuracy  0.294118\n1  Precision (Macro)  0.166217\n2  Precision (Micro)  0.294118\n3     Recall (Macro)  0.283019\n4     Recall (Micro)  0.294118\n5   F1 Score (Macro)  0.195642\n6   F1 Score (Micro)  0.294118\n7            ROC AUC       NaN","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Metric</th>\n      <th>Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Accuracy</td>\n      <td>0.294118</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Precision (Macro)</td>\n      <td>0.166217</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Precision (Micro)</td>\n      <td>0.294118</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Recall (Macro)</td>\n      <td>0.283019</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Recall (Micro)</td>\n      <td>0.294118</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>F1 Score (Macro)</td>\n      <td>0.195642</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>F1 Score (Micro)</td>\n      <td>0.294118</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>ROC AUC</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":51},{"cell_type":"markdown","source":"#### Word2Vec + SVM","metadata":{}},{"cell_type":"code","source":"model_w2v = Word2Vec(sentences=X_train['text_cleaned_words'], vector_size=100, window=5, min_count=1)\n\npreprocessor = ColumnTransformer(\n    transformers = [('text', Word2VecVectorizer(model_w2v), text_feature),\n                    ('num', StandardScaler(), num_features)],\n    remainder='drop'\n)\n\n\n\nsvm_w2v = Pipeline([\n    ('preprocessor', preprocessor),\n    ('classifier', LogisticRegression())\n])\n\n\n\nsvm_w2v.fit(X_train, y_train)\n\ny_pred = svm_w2v.predict(X_test)\nmetrics_svm_w2v = metrics(y_pred, y_test)\nmetrics_svm_w2v","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T18:54:02.374941Z","iopub.execute_input":"2024-12-11T18:54:02.375578Z","iopub.status.idle":"2024-12-11T18:55:20.878629Z","shell.execute_reply.started":"2024-12-11T18:54:02.375497Z","shell.execute_reply":"2024-12-11T18:55:20.876900Z"}},"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"              Metric     Score\n0           Accuracy  0.294118\n1  Precision (Macro)  0.165274\n2  Precision (Micro)  0.294118\n3     Recall (Macro)  0.283019\n4     Recall (Micro)  0.294118\n5   F1 Score (Macro)  0.194654\n6   F1 Score (Micro)  0.294118\n7            ROC AUC       NaN","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Metric</th>\n      <th>Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Accuracy</td>\n      <td>0.294118</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Precision (Macro)</td>\n      <td>0.165274</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Precision (Micro)</td>\n      <td>0.294118</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Recall (Macro)</td>\n      <td>0.283019</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Recall (Micro)</td>\n      <td>0.294118</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>F1 Score (Macro)</td>\n      <td>0.194654</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>F1 Score (Micro)</td>\n      <td>0.294118</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>ROC AUC</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":52},{"cell_type":"markdown","source":"Word2Vec показал себя хуже, чем более простые модели.","metadata":{}},{"cell_type":"markdown","source":"#### GloVe","metadata":{}},{"cell_type":"code","source":"# Получение векторов для каждого текста\ndef get_vector(text):\n    return np.mean([glove_vectors[word] for word in text if word in glove_vectors], axis=0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T18:55:20.880583Z","iopub.execute_input":"2024-12-11T18:55:20.881054Z","iopub.status.idle":"2024-12-11T18:55:20.897534Z","shell.execute_reply.started":"2024-12-11T18:55:20.881004Z","shell.execute_reply":"2024-12-11T18:55:20.894743Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"# Загрузка GloVe векторов\nglove_vectors = {}\nwith open('/kaggle/input/glove-text/glove.6B.100d.txt', 'r', encoding='utf-8') as f:\n    for line in f:\n        values = line.split()\n        word = values[0]\n        vector = np.array(values[1:], dtype='float32')\n        glove_vectors[word] = vector\n\nscaler = StandardScaler()\n\nX_train_glove = np.array([get_vector(text) for text in X_train['text_cleaned']])\nX_test_glove = np.array([get_vector(text) for text in X_test['text_cleaned']])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T18:55:20.899666Z","iopub.execute_input":"2024-12-11T18:55:20.900288Z","iopub.status.idle":"2024-12-11T18:56:38.401275Z","shell.execute_reply.started":"2024-12-11T18:55:20.900224Z","shell.execute_reply":"2024-12-11T18:56:38.400042Z"}},"outputs":[],"execution_count":54},{"cell_type":"code","source":"log_reg = LogisticRegression(random_state=RANDOM_STATE)\nlog_reg.fit(X_train_glove, y_train)\n\ny_pred = log_reg.predict(X_test_glove)\n\nlog_reg_glove = metrics(y_pred, y_test)\nlog_reg_glove","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T18:56:38.402971Z","iopub.execute_input":"2024-12-11T18:56:38.403906Z","iopub.status.idle":"2024-12-11T18:56:43.982415Z","shell.execute_reply.started":"2024-12-11T18:56:38.403853Z","shell.execute_reply":"2024-12-11T18:56:43.977159Z"}},"outputs":[{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"              Metric     Score\n0           Accuracy  0.019608\n1  Precision (Macro)  0.000392\n2  Precision (Micro)  0.019608\n3     Recall (Macro)  0.019608\n4     Recall (Micro)  0.019608\n5   F1 Score (Macro)  0.000769\n6   F1 Score (Micro)  0.019608\n7            ROC AUC       NaN","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Metric</th>\n      <th>Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Accuracy</td>\n      <td>0.019608</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Precision (Macro)</td>\n      <td>0.000392</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Precision (Micro)</td>\n      <td>0.019608</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Recall (Macro)</td>\n      <td>0.019608</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Recall (Micro)</td>\n      <td>0.019608</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>F1 Score (Macro)</td>\n      <td>0.000769</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>F1 Score (Micro)</td>\n      <td>0.019608</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>ROC AUC</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":55},{"cell_type":"markdown","source":"# Выводы","metadata":{}},{"cell_type":"code","source":"all_metrics = pd.concat([baseline_metrics.T.loc['Score'], lexicon_based_metrics.T.loc['Score'], rule_based_metrics.T.loc['Score'], \n                        log_reg_bow_metrics.T.loc['Score'], log_reg_tfidf_metrics.T.loc['Score'], log_reg_bow_ngram_metrics.T.loc['Score'], svc_bow_metrics.T.loc['Score'],\n                        SVM_tfidf_metrics.T.loc['Score'], naive_bayes_BoW_metrics.T.loc['Score'], metrics_w2v_log_reg.T.loc['Score'], metrics_svm_w2v.T.loc['Score'], log_reg_glove.T.loc['Score']], axis=1).T\n\nall_metrics.columns = ['Accuracy', 'Precision (Macro)', 'Precision (Micro)', 'Recall (Macro)', 'Recall (Micro)', 'F1 Score (Macro)', 'F1 Score (Micro)', 'ROC AUC']\nall_metrics.index = ['baseline', 'lexicon_based', 'rule_based', 'log_reg_bow', 'log_reg_tfidf', 'log_reg_bow_ngram', 'svc_bow', 'svc_tfidf', 'naive_bayes_BoW', 'log_reg_w2v',\n                    'svm_w2v', 'log_reg_glove']\n\nall_metrics.sort_values(by=['Accuracy', 'F1 Score (Macro)', 'F1 Score (Micro)'], ascending=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T18:56:43.985855Z","iopub.execute_input":"2024-12-11T18:56:43.986451Z","iopub.status.idle":"2024-12-11T18:56:44.068722Z","shell.execute_reply.started":"2024-12-11T18:56:43.986392Z","shell.execute_reply":"2024-12-11T18:56:44.067530Z"}},"outputs":[{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"                   Accuracy Precision (Macro) Precision (Micro)  \\\nnaive_bayes_BoW    0.647059          0.505747          0.647059   \nlog_reg_tfidf      0.568627          0.442949          0.568627   \nlexicon_based      0.568627          0.450292          0.568627   \nlog_reg_bow         0.54902          0.399691           0.54902   \nlog_reg_bow_ngram  0.529412          0.410303          0.529412   \nsvc_tfidf          0.509804          0.400744          0.509804   \nsvc_bow            0.490196          0.379245          0.490196   \nlog_reg_w2v        0.294118          0.166217          0.294118   \nsvm_w2v            0.294118          0.165274          0.294118   \nrule_based         0.058824          0.032308          0.058824   \nlog_reg_glove      0.019608          0.000392          0.019608   \nbaseline           0.019608          0.000384          0.019608   \n\n                  Recall (Macro) Recall (Micro) F1 Score (Macro)  \\\nnaive_bayes_BoW         0.568966       0.647059         0.525862   \nlog_reg_tfidf           0.557692       0.568627         0.474359   \nlexicon_based           0.508772       0.568627         0.467836   \nlog_reg_bow             0.518519        0.54902         0.432451   \nlog_reg_bow_ngram       0.490909       0.529412         0.430303   \nsvc_tfidf               0.472727       0.509804         0.416364   \nsvc_bow                 0.471698       0.490196         0.401903   \nlog_reg_w2v             0.283019       0.294118         0.195642   \nsvm_w2v                 0.283019       0.294118         0.194654   \nrule_based              0.046154       0.058824         0.033566   \nlog_reg_glove           0.019608       0.019608         0.000769   \nbaseline                0.019608       0.019608         0.000754   \n\n                  F1 Score (Micro) ROC AUC  \nnaive_bayes_BoW           0.647059     NaN  \nlog_reg_tfidf             0.568627     NaN  \nlexicon_based             0.568627     NaN  \nlog_reg_bow                0.54902     NaN  \nlog_reg_bow_ngram         0.529412     NaN  \nsvc_tfidf                 0.509804     NaN  \nsvc_bow                   0.490196     NaN  \nlog_reg_w2v               0.294118     NaN  \nsvm_w2v                   0.294118     NaN  \nrule_based                0.058824     NaN  \nlog_reg_glove             0.019608     NaN  \nbaseline                  0.019608     NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Accuracy</th>\n      <th>Precision (Macro)</th>\n      <th>Precision (Micro)</th>\n      <th>Recall (Macro)</th>\n      <th>Recall (Micro)</th>\n      <th>F1 Score (Macro)</th>\n      <th>F1 Score (Micro)</th>\n      <th>ROC AUC</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>naive_bayes_BoW</th>\n      <td>0.647059</td>\n      <td>0.505747</td>\n      <td>0.647059</td>\n      <td>0.568966</td>\n      <td>0.647059</td>\n      <td>0.525862</td>\n      <td>0.647059</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>log_reg_tfidf</th>\n      <td>0.568627</td>\n      <td>0.442949</td>\n      <td>0.568627</td>\n      <td>0.557692</td>\n      <td>0.568627</td>\n      <td>0.474359</td>\n      <td>0.568627</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>lexicon_based</th>\n      <td>0.568627</td>\n      <td>0.450292</td>\n      <td>0.568627</td>\n      <td>0.508772</td>\n      <td>0.568627</td>\n      <td>0.467836</td>\n      <td>0.568627</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>log_reg_bow</th>\n      <td>0.54902</td>\n      <td>0.399691</td>\n      <td>0.54902</td>\n      <td>0.518519</td>\n      <td>0.54902</td>\n      <td>0.432451</td>\n      <td>0.54902</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>log_reg_bow_ngram</th>\n      <td>0.529412</td>\n      <td>0.410303</td>\n      <td>0.529412</td>\n      <td>0.490909</td>\n      <td>0.529412</td>\n      <td>0.430303</td>\n      <td>0.529412</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>svc_tfidf</th>\n      <td>0.509804</td>\n      <td>0.400744</td>\n      <td>0.509804</td>\n      <td>0.472727</td>\n      <td>0.509804</td>\n      <td>0.416364</td>\n      <td>0.509804</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>svc_bow</th>\n      <td>0.490196</td>\n      <td>0.379245</td>\n      <td>0.490196</td>\n      <td>0.471698</td>\n      <td>0.490196</td>\n      <td>0.401903</td>\n      <td>0.490196</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>log_reg_w2v</th>\n      <td>0.294118</td>\n      <td>0.166217</td>\n      <td>0.294118</td>\n      <td>0.283019</td>\n      <td>0.294118</td>\n      <td>0.195642</td>\n      <td>0.294118</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>svm_w2v</th>\n      <td>0.294118</td>\n      <td>0.165274</td>\n      <td>0.294118</td>\n      <td>0.283019</td>\n      <td>0.294118</td>\n      <td>0.194654</td>\n      <td>0.294118</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>rule_based</th>\n      <td>0.058824</td>\n      <td>0.032308</td>\n      <td>0.058824</td>\n      <td>0.046154</td>\n      <td>0.058824</td>\n      <td>0.033566</td>\n      <td>0.058824</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>log_reg_glove</th>\n      <td>0.019608</td>\n      <td>0.000392</td>\n      <td>0.019608</td>\n      <td>0.019608</td>\n      <td>0.019608</td>\n      <td>0.000769</td>\n      <td>0.019608</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>baseline</th>\n      <td>0.019608</td>\n      <td>0.000384</td>\n      <td>0.019608</td>\n      <td>0.019608</td>\n      <td>0.019608</td>\n      <td>0.000754</td>\n      <td>0.019608</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":56}]}