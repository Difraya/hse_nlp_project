# Определение авторства текстов
Годовой проект студентов 1 года магистратуры "Искусственный интеллект" НИУ ВШЭ (2024 - 2025 гг.)
## Описание проекта
Создать ML сервис, определяющий 1-го или несколько возможных авторов текста по небольшому фрагменту. 
## Команда
 Куратор проекта: Бурлова Альбина (tg@planqua, [GitHub](https://github.com/AlbinaBurlova))
- Лялин Дмитрий (tg@dslyalin, [GitHub](https://github.com/dslialin))
- Смиян Юлия (tg@kusyaku, [GitHub](https://github.com/Difraya))
- Хибин Вадим (tg@VadimKhibin, [GitHub](https://github.com/1vad1mka))
- Вороник Виталий (tg@Vorvit, [GitHub](https://github.com/vorvit))
## Краткое описание проекта
Данный проект представляет собой приложение для предсказания авторов по тексту. Мы собрали данные о 100 наиболее популярных авторов в мировой литературе, обучили классические ML-модели, которые позволяют предсказывать авторство по тексту и сделали MVP-приложение, используя FastAPI, streamlit и Docker.

Чтобы приложение работало нужно:
1. клонировать содержимое репозитория;
2. установить зависимости из `requirements.txt`;
3. запустить скрипт `download_files.py` , чтобы скачать необходимые данные;
4. пользоваться приложением.


На сервер изначально загружено 4 модели. 

Более подробная инструкция и демонстрация работы расположена в файле `report.pdf`.


## Docker: инструкция
Для создания docker-образа и запуска контейнеров с приложениями, в операционной системе Windows необходимо:
1. Запустить Docker engine.
2. Пройти в папку streamlit и заменить переменную в 20-й строке файла streamlit_nlp.py, на: API_URL = "http://fastapi:8000".
3. Перейти в корневой каталог склонированного репозитория запустить команду docker-compose up.
4. Дождаться запуска контейнеров и перейти по адресу 127.0.0.1:8501- для streamlit, или 127.0.0.1:8000 - для FastAPI.

Далее можно пользоваться приложением.


### Основные endpoint'ы FastAPI
### `/ (root)`
В корневом маршруте реализован базовый **FastAPI AJAX Interface** без перезагрузки страницы, который позволяет выбрать модель из обученных, быстро сделать предсказание автора по вручную написанному тексту или по файлу. Вот пример:

Мы мы можем выбрать модель из выпадающего списка:
![[Pasted image 20250103162041.png]]

Затем можно ввести какой-то текст и получить предсказание:
![[Pasted image 20250103162255.png]]


Если текст большой, то можно загрузить текст файлом и сделать предсказание:
![[Pasted image 20250103162427.png]]


На вход принимается текст, далее нужно нажать на кнопку `Submit`. После этого получим предсказание автора. В данном случае - Достоевского.


### `/ModelsList`
На сервер изначально загружено 4 уже обученных модели-пайплайна с автоматической обработкой текста, удалением стоп-слов, токенизацией и возможностью предсказания. 

Чтобы посмотреть все изначально загруженные модели с уникальным ID и описанием, достаточно отправить `GET`-запрос по маршруту `/ModelsList`:
![[Pasted image 20250102183819.png|650]]

Можно видеть структуру пайплайнов, что позволяет пользователю выбрать подходящую модель и подходящие для нее гиперпараметры. 


### `/SetModels`
Чтобы использовать какую-либо модель для inference'а или для переобучения/дообучения, нужно отправить `POST`-запрос по маршруту `/setModel` , указав уникальный `id` модели:
![[Pasted image 20250102184351.png|550]]

Если модель была сделана активной, то пользователю вернется соответствующие сообщение и код `200`.


### `/PredictItem`
Чтобы предсказать автора по одному тексту (как правило, короткому тексту, т.к. для длинных текстов реализованы endpoint'ы для приема файлов), нужно отправить `POST`-запрос по маршруту `/PredictItem` , отправив текст в формате json:
```json
{
	"text": "<какой-то текст>"
}
```

Например, можно отправить какой-то текст Достоевского и посмотреть на предсказания:
![[Pasted image 20250102190855.png|550]]

На выходе получаем response в формате JSON следующей структуры:
```json
{
	"id": "<id модели>",
	"author": "<автор>"
}
```


### `/PredictItemFile`
Данный endpoint нужно использовать, когда текст для предсказания слишком большой. Чтобы совершить предсказание, нужно совершить `POST`-запрос по маршруту `/PredictItemFile`, отправив файл с текстом в формате `.txt`. Вот пример запроса с файлом `PredictItemTestData.txt` :
![[Pasted image 20250102191451.png|600]]

В результате получаем response в формате JSON такой структуры:
```json
{
	"id": "<id модели>",
	"author": "<автор>"
}
```


### `/PredictItemProba`
Чтобы предсказать вероятности возможных авторов по короткому тексту, нужно отправить `POST`-запрос по маршруту `/PredictItemProba` с JSON следующего формата:
```json
{
	"text": "<какой-то текст>"
}
```

Вот пример отправки текста для оценки вероятностей:
![[Pasted image 20250102191703.png|600]]

На выходе получается JSON-response с вероятностями для каждого автора из обучающей выборки, который имеет такую структуру:
```json
{
	"<имя автора 1>": <float со значением вероятности автора1>,
	"<имя автора 2>": <float со значением вероятности автора2>,
	...
}
```



### `/PredictItemProbaFile`
Этот endpoint используется для предсказания вероятностей авторов по тексту, оформленному в файл формата `.txt`. Нужно отправить `POST`-запрос с соответствующем файлом.

Пример отправки отрывка теста Достоевского в файле `PredictItemTestData.txt` :
![[Pasted image 20250102192350.png|550]]

В результате получаем ответ в формате JSON:
```json
{
	"<имя автора 1>": <float со значением вероятности автора1>,
	"<имя автора 2>": <float со значением вероятности автора2>,
	...
}
```


### `/PredictItems`
Если нужно предсказать авторов сразу нескольких коротких текстов, используется `POST`-запрос по маршруту `/PredictItems`. В качестве request'а нужно передать JSON следующей структуры:
```json
{
  "texts": {
    "<id текста1>": "<текст1>",
    "<id текста2>": "<текст2>",
    "<id текста3>": "<текст3>"
  }
}
```

Вот пример отправки подобного запроса:
![[Pasted image 20250102192907.png|550]]

В результате получается response в таком формате:
```json
{
  "response": {
    "<id текста1>": "<автор текста1>",
    "<id текста2>": "<автор текста2>",
    "<id текста3>": "<автор текста3>",
    ...
  }
}
```


### `/PredictItemsProba`
Чтобы предсказать вероятности авторов для нескольких текстов, нужно отправить `POST`-запрос с JSON'ом следующей структуры:
```json
{
  "texts": {
    "<id текста1>": "<текст1>",
    "<id текста2>": "<текст2>",
    "<id текста3>": "<текст3>",
    ...
  }
}
```

Вот пример отправки запроса со случайными текстами:
![[Pasted image 20250102194002.png|550]]

В качестве response'а получается JSON следующей структуры:
```
{"response": 
	{"<текст1>": {"<автор1>": <вероятность автора1>,
				  "<автор2>": <вероятность автора2>,
				  ...
				  }, 
	},
	{"<текст2>": {"<автор1>": <вероятность автора1>,
				  "<автор2>": <вероятность автора2>,
				  ...
				  }, 
	},
	...
}
```


### `/train_model`
Данный endpoint предназначен для переобучения (refit'а) модели из списка, а также возвращения значений кривых обучения. Он принимает следующие параметры, передаваемые `POST`-запросом:

- **`request`** (`str`) : строка-json с гиперпараметрами для модели в формате, указанном ниже;
```JSON
{"hyperparameters": 
	{
	"<гиперпараметр1>": <значение гиперпараметра 1>,
	"<гиперпараметр2>": <значение гиперпараметра 2>,
	...
	}
}
```

- **`train_file`** : тренировочный датасет формата `.parquet` , который должен иметь 2 столбца (`text` - текст автора и `author` - имя автора, целевая переметра);

- **`test_file`** : тестовый датасет формата `.parquet` , который также имеет 2 столбца (`text` - текст автора и `author` - имя автора, целевая переменная).


Вот пример запроса:
![[Pasted image 20250103172332.png|600]]


В качестве response'а возвращается JSON следующей структуры:
```JSON
{
	"model_id": "<id модели>",
	"execution_time": "<время>",
	"accuracy": "<значение accuracy>",
	"precision": "<значение precision>",
	"recall": "<значение recall>",
	"f1": "<значение f1>",
	"train_sizes": [...],
	"train_scores_mean": [...],
	"test_scores_mean": [...]
}
```

То есть модель переобучна, её результативность можно увидеть. Также можно построить кривые обучения.


### `/partial_fit`
Данный endpoint предназначен для дообучения модели. На данный момент дообучение возможно только для `model4`. Чтобы дообучить модель, нужно передать в `POST`-запрос следующие параметры:

- `id` - строка с `id` модели, которая будет дообучаться;
- `request_file` : файл формата `.parquet` , имеющий 2 столбца (`text` - текст автора и `author` - имя автора, целевая переменная).


Вот пример для обучения:
![[Pasted image 20250102215013.png|600]]

В качестве response приходит JSON такого формата:
```JSON
{"message": "Model with id '<id модели>' successfully updated with new data."}
```


После обучения можно увидеть, что новая модель доступна теперь для инференса. Можно выбрать её и сделать предсказание:
![[Pasted image 20250103164333.png|550]]


### `/fine_tuning`
Чтобы дообучить все модели новыми данными, нужно использовать этот endpoint. Нужно просто прикрепить файл с новыми данными в формате `.parquet`. В нем должны быть колонки `text` и `author`.

Вот пример запроса:
![[Pasted image 20250103171349.png|600]]

Теперь все модели переобучены. То есть пользователь может легко обучить все модели на своих данных.



## Streamlit
### Краткое описание
Наше Streamlit-приложение предоставляет удобный интерфейс для анализа текстов и предсказания их авторства. Оно включает в себя базовые инструменты для обработки текста, визуализации, а также функции предсказания и обучения/дообучения моделей машинного обучения. Приложение ориентировано на работу с текстовыми данными и поддерживает выбор готовых моделей, а также загрузку пользовательских данных для дообучения.

### Системные требования
Главные системные требования:
- Python 3.12 или выше.
- Streamlit 1.20 или выше.
- NLTK и дополнительные пакеты (punkt, stopwords, averaged_perceptron_tagger).
- Установленный сервер API с поддержкой предсказаний.

Установка зависимостей:
```
pip install -r requirements.txt
```


Запуск приложения:
```
streamlit run streamlit_nlp.py
```


Примеры команд для API
Предсказание авторства текста:
```
curl -X POST "http://127.0.0.1:8000/PredictItem" 
	 -H "Content-Type: application/json" 
	 -d '{"text": "Пример текста"}'
```


Загрузка файла и предсказание:
```
curl -X POST "http://127.0.0.1:8000/PredictItemFile" 
	 -F "request=@example.txt"
```


### Техническая реализаций (Языки и библиотеки)
Приложение написано на Python 3.12+ с использованием следующих библиотек:
- **`Streamlit`** — создание веб-интерфейса.
- **`NLTK`** — обработка текста (токенизация, POS-теги, n-граммы).
- **`Pandas`** — работа с табличными данными.
- **`Plotly`** — построение интерактивных графиков.
- **`Requests`** — взаимодействие с REST API.
- **`JSON`** — обработка гиперпараметров.


### Архитектура
Приложение разделено на три основные вкладки, каждая из которых реализует свою логику:

**_I. Пользовательская часть_**
Функционал:
- Анализ текста, включая:
- Подсчёт количества слов, уникальных слов и знаков препинания.
- Построение гистограмм по частям речи и n-граммам (1–3).
- Преобразование текста с удалением стоп-слов для подготовки данных.
- Интеграция с API для предсказания авторства текста и вероятностных оценок.
- Поддержка загрузки файлов в формате .txt для пакетной обработки.

Ключевые функции:
- **`get_top_words`** — получение наиболее частотных слов.
- **`get_ngrams`** — генерация n-грамм.
- **`most_common_ngrams`** — подсчёт самых популярных n-грамм.
- **`del_stopwords`** — удаление стоп-слов.
- **`get_pos`** — анализ частей речи.
- **`punctuation`** — подсчёт знаков препинания.

API-интеграция:
- POST-запросы для передачи текста или файла в REST API и получения предсказаний.

**_II. Информация про модели и данные_**
Функционал:
- Запрос списка доступных моделей с описанием.
- Установка активной модели для работы с текстами.
API-интеграция:
- GET-запрос для получения списка моделей.
- POST-запрос для выбора активной модели.


**III. Обучи свою модель**
Функционал:
- Загрузка пользовательских данных в формате .parquet.
- Настройка гиперпараметров через текстовое поле (JSON).
- Вызов API для обучения новой модели.
- Поддержка дообучения (partial_fit) на новых данных.
API-интеграция:
- POST-запросы с файлами данных и гиперпараметрами для обучения.
- Обработка ошибок в API и вывод логов для отладки.


Приложение работает с REST API по адресу http://127.0.0.1:8000. Основные эндпоинты можно посмотреть выше.

Форматы данных:
- Печатный текст
- JSON для текстов и параметров.
- Multipart/form-data для файлов.







